{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "TEST_DUMMY_API_KEY = os.getenv('TEST_DUMMY_API_KEY_STA')\n",
    "TEST_DUMMY_API_URL = os.getenv('TEST_DUMMY_API_URL_STA')\n",
    "\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = TEST_DUMMY_API_KEY, \n",
    "            api_url = TEST_DUMMY_API_URL)\n",
    "\n",
    "import json\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some minor notes before starting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the flexibility we've added with true modularity, we need to be sticklers about input format.\n",
    "\n",
    "We'll talk more about this later.  But for now - if you want to input a `json` of your own design first study how the examples look in the `input_files` directory.  Copy that pattern or your input won't upload.\n",
    "\n",
    "Also - this is a playground version.  Not all tests have been completely carried over to our new modular system.  So you break it you buy it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make usage easier define an\n",
    "\n",
    "- input path to your test data files\n",
    "- a local_save_directory for your output files\n",
    "- a directory for your pipeline configs\n",
    "\n",
    "Lets do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory for input files \n",
    "input_directory = 'input_files'\n",
    "\n",
    "# define directory for output files\n",
    "output_directory = 'output_files'\n",
    "\n",
    "# define directory for pipeline_configs\n",
    "pipeline_configs_directory = 'pipeline_configs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Converting pdf to text...\n",
      "SUCCESS: File conversion complete with pydf, result saved to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpxawcel9c/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted input_files/chapter_1_short.pdf to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpxawcel9c/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: hydrated input modules: {'parser': {'model': 'fixed', 'params': {'chunk_size': 10, 'overlap_size': 2}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-search': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_qmnoqbmjre.txt\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 180 seconds, at Tue Apr 16 05:27:18 2024 UTC\n",
      "INFO: vector-pipeline-1 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: ea5f107d-8591-bc0b-64b3-a2d5cfe6baa1\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 3) - parser processing complete.\n",
      "SUCCESS: module 2 (of 3) - text-embedder processing complete.\n",
      "SUCCESS: module 3 (of 3) - vector-search processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# create modules for text (vector) search\n",
    "module_1 = Module(name=\"parser\")\n",
    "module_2 = Module(name=\"text-embedder\")\n",
    "module_3 = Module(name=\"vector-search\")\n",
    "\n",
    "# create your custom pipeline\n",
    "custom = CreatePipeline(name='vector-pipeline-1', \n",
    "                        module_chain=[module_1, module_2, module_3])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config - we'll do below)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)\n",
    "\n",
    "# define a test file in your input_files directory\n",
    "test_file = \"chapter_1_short.pdf\"\n",
    "\n",
    "# process the file\n",
    "output = pipeline.process(local_file_path = input_directory + \"/\" + test_file,\n",
    "                             expire_time=60*3, # have the output expire in 3 minutes\n",
    "                             modules={},  # purposefully placing modules={}, they are hydrated in as necessary, see printout \n",
    "                             local_save_directory=output_directory)  # save the output to the output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the last line \n",
    "\n",
    "```SUCCESS: process output downloaded```\n",
    "\n",
    "Whats the \"process output\" of the pipeline?  Its not json right - that comes from using `vector_search`.  \n",
    "\n",
    "Its the vector search database itself.\n",
    "\n",
    "Now that our pipelines are truly modular people need to be able to pass input and get output from any module.  More generally - they need to be able to pass input into any first module they choose for a pipeline, and retrieve output from its final module.  For all modules.\n",
    "\n",
    "(We (kinda) did this previously - but only for pipelines whose final module produced `json` output - e.g., transcribe (a one module pipeline).  That was bespoke wiring.  And we didn't download json, we passed it back to the cli via the request.)  \n",
    "\n",
    "For example - what if the pipeline ends with `text-embedder`?  Well - as you suggested a while back - the user would need to get back the embeddings.  (and then - if you had another pipeline that began with `vector-search` - how would you be able to use it as a single module pipeline if you couldn't upload embeddings to it?).\n",
    "\n",
    "So in any event - now that our pipelines are truly modular, users `.fetch_output` needs to return the output of every possible module.  Now it does.\n",
    "\n",
    "And by default `.process` calls `.fetch_output` as it finishes (that hasn't changed).\n",
    "\n",
    "\n",
    "Fine.  Back to our pipeline here.\n",
    "\n",
    "For our standard vector search pipeline the output of `vector-search` is a `.faiss` database.\n",
    "\n",
    "If you look in the `output_files` directory you can see the file.  It is named `{file_id}.faiss`.  Likewise, every output is called `{file_id}.{its_extension}`.\n",
    "\n",
    "\n",
    "Fine.\n",
    "\n",
    "In any event - now we can use our `vector_search` api on this pipeline since it ends with the `vector-search` module and we just processed a file through it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_code': 200,\n",
       " 'request_id': 'f4021539-f480-4914-8c50-11a6bcd3a149',\n",
       " 'message': 'Successfully queried 2 user files.',\n",
       " 'warnings': [],\n",
       " 'items': [{'file_id': 'ca71efb3-bce4-4539-be9f-f85bc778561f',\n",
       "   'file_metadata': {'file_name': 'krixik_generated_cfcxwtdsnp.txt',\n",
       "    'symbolic_directory_path': '/etc',\n",
       "    'file_tags': [],\n",
       "    'num_vectors': 43,\n",
       "    'created_at': '2024-04-13 21:30:02',\n",
       "    'last_updated': '2024-04-13 21:30:02'},\n",
       "   'search_results': [{'snippet': 'cats and dogs? Intuitively, when',\n",
       "     'line_numbers': [32],\n",
       "     'distance': 0.235},\n",
       "    {'snippet': 'etc.) are either cats or dogs, until they fully grasp',\n",
       "     'line_numbers': [30, 31],\n",
       "     'distance': 0.247},\n",
       "    {'snippet': 'of cats from those with dogs . This will allow',\n",
       "     'line_numbers': [20],\n",
       "     'distance': 0.261},\n",
       "    {'snippet': 'a computer how to distinguish between pic- tures of cats',\n",
       "     'line_numbers': [19, 20],\n",
       "     'distance': 0.277},\n",
       "    {'snippet': 'learned about the di â†µerence between cats and dogs, and',\n",
       "     'line_numbers': [23, 24],\n",
       "     'distance': 0.291}]},\n",
       "  {'file_id': '0bb4de37-1238-4d34-8c69-cee5fd2b0e3a',\n",
       "   'file_metadata': {'file_name': 'krixik_generated_cckuijwneg.txt',\n",
       "    'symbolic_directory_path': '/etc',\n",
       "    'file_tags': [],\n",
       "    'num_vectors': 43,\n",
       "    'created_at': '2024-04-13 21:29:22',\n",
       "    'last_updated': '2024-04-13 21:29:22'},\n",
       "   'search_results': [{'snippet': 'cats and dogs? Intuitively, when',\n",
       "     'line_numbers': [32],\n",
       "     'distance': 0.235},\n",
       "    {'snippet': 'etc.) are either cats or dogs, until they fully grasp',\n",
       "     'line_numbers': [30, 31],\n",
       "     'distance': 0.247},\n",
       "    {'snippet': 'of cats from those with dogs . This will allow',\n",
       "     'line_numbers': [20],\n",
       "     'distance': 0.261},\n",
       "    {'snippet': 'a computer how to distinguish between pic- tures of cats',\n",
       "     'line_numbers': [19, 20],\n",
       "     'distance': 0.277},\n",
       "    {'snippet': 'learned about the di â†µerence between cats and dogs, and',\n",
       "     'line_numbers': [23, 24],\n",
       "     'distance': 0.291}]}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector search the file\n",
    "pipeline.vector_search(query=\"do you like cats\",\n",
    "                       symbolic_directory_paths = [\"/*\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goody gumdrops.\n",
    "\n",
    "Now above we built our custom pipeline object (`custom`) and passed it directly to our `krixik` factory operator.\n",
    "\n",
    "As we discussed, probably best to be able to save that `custom` object as a configuration file for easier re-use.\n",
    "\n",
    "You can create the same pipeline by first saving the `custom` config, then re-loading it.  I'll show you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Converting pdf to text...\n",
      "SUCCESS: File conversion complete with pydf, result saved to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpiltsoj1d/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted input_files/chapter_1_short.pdf to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpiltsoj1d/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: hydrated input modules: {'parser': {'model': 'fixed', 'params': {'chunk_size': 10, 'overlap_size': 2}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-search': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_nctsdcedmm.txt\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 180 seconds, at Sat Apr 13 14:44:49 2024 UTC\n",
      "INFO: vector-pipeline-1 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: d039302e-60d0-8c01-01be-073d330f77cc\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 3) - parser processing complete.\n",
      "SUCCESS: module 2 (of 3) - text-embedder processing complete.\n",
      "SUCCESS: module 3 (of 3) - vector-search processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# save the configuration of our custom pipeline object\n",
    "custom.save(pipeline_configs_directory + \"/\" + \"vector-pipeline-1.yaml\")\n",
    "\n",
    "# instantiate our krixik factory processor by re-loading the config from file\n",
    "pipeline = krixik.load_pipeline(config_path=pipeline_configs_directory + \"/\" + \"vector-pipeline-1.yaml\")\n",
    "\n",
    "# from here - same steps as shown above\n",
    "\n",
    "# define a test file in your input_files directory\n",
    "test_file = \"chapter_1_short.pdf\"\n",
    "\n",
    "# process the file\n",
    "output = pipeline.process(local_file_path = input_directory + \"/\" + test_file,\n",
    "                             expire_time=60*3, # have the output expire in 3 minutes\n",
    "                             modules={},  # purposefully placing modules={}, they are hydrated in as necessary, see printout \n",
    "                             local_save_directory=output_directory)  # save the output to the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_code': 200,\n",
       " 'request_id': 'ea9dd67a-bb20-48a8-9968-1927f0974b0d',\n",
       " 'message': 'Successfully queried 1 user file.',\n",
       " 'warnings': [],\n",
       " 'items': [{'file_id': '572185a8-be42-4582-a547-d0222b341871',\n",
       "   'file_metadata': {'file_name': 'krixik_generated_nctsdcedmm.txt',\n",
       "    'symbolic_directory_path': '/etc',\n",
       "    'file_tags': [],\n",
       "    'num_vectors': 43,\n",
       "    'created_at': '2024-04-13 21:41:53',\n",
       "    'last_updated': '2024-04-13 21:41:53'},\n",
       "   'search_results': [{'snippet': 'cats and dogs? Intuitively, when',\n",
       "     'line_numbers': [32],\n",
       "     'distance': 0.235},\n",
       "    {'snippet': 'etc.) are either cats or dogs, until they fully grasp',\n",
       "     'line_numbers': [30, 31],\n",
       "     'distance': 0.247},\n",
       "    {'snippet': 'of cats from those with dogs . This will allow',\n",
       "     'line_numbers': [20],\n",
       "     'distance': 0.261},\n",
       "    {'snippet': 'a computer how to distinguish between pic- tures of cats',\n",
       "     'line_numbers': [19, 20],\n",
       "     'distance': 0.277},\n",
       "    {'snippet': 'learned about the di â†µerence between cats and dogs, and',\n",
       "     'line_numbers': [23, 24],\n",
       "     'distance': 0.291}]}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector search the file\n",
    "pipeline.vector_search(query=\"do you like cats\",\n",
    "                       symbolic_directory_paths = [\"/*\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword search\n",
    "\n",
    "Like we discussed, keyword search has been spun off into its own module.\n",
    "\n",
    "If you're uploading a text file, its now a one module pipeline.  Lets see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Converting pdf to text...\n",
      "SUCCESS: File conversion complete with pydf, result saved to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmp5fxec6la/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted input_files/chapter_1_short.pdf to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmp5fxec6la/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: hydrated input modules: {'keyword-search': {'model': 'base', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_dzzhhiprkd.txt\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 180 seconds, at Sat Apr 13 14:46:54 2024 UTC\n",
      "INFO: keyword-pipeline-1 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: 57ea3ec2-a24a-e83f-6436-3674ad0b0335\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 1) - keyword-search processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# create modules for text (vector) search\n",
    "module_1 = Module(name=\"keyword-search\")\n",
    "\n",
    "# create your custom pipeline\n",
    "custom = CreatePipeline(name='keyword-pipeline-1', \n",
    "                        module_chain=[module_1])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config - we'll do below)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)\n",
    "\n",
    "# define a test file in your input_files directory\n",
    "test_file = \"chapter_1_short.pdf\"\n",
    "\n",
    "# process the file\n",
    "output = pipeline.process(local_file_path = input_directory + \"/\" + test_file,\n",
    "                             expire_time=60*3, # have the output expire in 3 minutes\n",
    "                             modules={},  # purposefully placing modules={}, they are hydrated in as necessary, see printout \n",
    "                             local_save_directory=output_directory)  # save the output to the output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again notice the \n",
    "\n",
    "```SUCCESS: process output downloaded```\n",
    "\n",
    "That's not a json, thats a sqlite database (extension `.db`).  Look in your `local_save_directory` and you'll see a file called `{file_id}.db`.  That's it.\n",
    "\n",
    "\n",
    "Now lets keyword search our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_code': 200,\n",
       " 'request_id': '6e4e62c9-f61a-4e95-9615-bca238ee323e',\n",
       " 'message': 'Successfully queried 1 user file.',\n",
       " 'warnings': [{'WARNING: the following words in the query are in the stop_words list and thus no results will be returned for them': ['do',\n",
       "    'you']}],\n",
       " 'items': [{'file_id': 'c282820d-0699-4baa-93fe-5bb7324459a9',\n",
       "   'file_metadata': {'file_name': 'krixik_generated_dzzhhiprkd.txt',\n",
       "    'symbolic_directory_path': '/etc',\n",
       "    'file_tags': [],\n",
       "    'num_lines': 32,\n",
       "    'created_at': '2024-04-13 21:43:56',\n",
       "    'last_updated': '2024-04-13 21:43:56'},\n",
       "   'search_results': [{'keyword': 'cats',\n",
       "     'line_number': 16,\n",
       "     'keyword_number': 3},\n",
       "    {'keyword': 'cats', 'line_number': 20, 'keyword_number': 3},\n",
       "    {'keyword': 'cats', 'line_number': 23, 'keyword_number': 13},\n",
       "    {'keyword': 'like', 'line_number': 25, 'keyword_number': 8},\n",
       "    {'keyword': 'cats', 'line_number': 28, 'keyword_number': 11},\n",
       "    {'keyword': 'cats', 'line_number': 30, 'keyword_number': 15},\n",
       "    {'keyword': 'cats', 'line_number': 32, 'keyword_number': 6}]}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector search the file\n",
    "pipeline.keyword_search(query=\"do you like cats\",\n",
    "                        symbolic_directory_paths = [\"/*\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final note.\n",
    "\n",
    "If your input was a list of dictionaries (a json), you could attach `json-to-txt` to the front of this pipeline to create a keyword search pipeline for your json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few longer examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do one or two more long ones and then i'll leave you with my current laundary list of multi module pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}, 'translate': {'model': 'opus-mt-en-es', 'params': {}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-search': {'model': 'faiss', 'params': {}}}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "file size is less than 1e-05 megabytes (current minimum size allowable) or greater than 3.000001 megabytes (current maximum size allowable) - input_files/too_long.mp3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/validators/data/utilities/decorators.py:39\u001b[0m, in \u001b[0;36mdatatype_validator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp3\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mis_audio_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp4\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/validators/data/audio.py:75\u001b[0m, in \u001b[0;36mis_size\u001b[0;34m(local_file_path, minimum_seconds, maximum_seconds, minimum_file_size, maximum_file_size)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/validators/data/audio.py:62\u001b[0m, in \u001b[0;36mis_size\u001b[0;34m(local_file_path, minimum_seconds, maximum_seconds, minimum_file_size, maximum_file_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_size \u001b[38;5;241m<\u001b[39m minimum_file_size \u001b[38;5;129;01mor\u001b[39;00m file_size \u001b[38;5;241m>\u001b[39m maximum_file_size:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile size is less than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminimum_file_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m megabytes (current minimum size allowable) or greater than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaximum_file_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m megabytes (current maximum size allowable) - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# compute length of audio file in seconds\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: file size is less than 1e-05 megabytes (current minimum size allowable) or greater than 3.000001 megabytes (current maximum size allowable) - input_files/too_long.mp3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/validators/utilities/decorators.py:16\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msystem_base_type_check_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_data_type_check_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatatype_validator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlower_case_decorator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/validators/system/base/utilities/decorators.py:151\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(e)\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/validators/system/data/utilities/decorators.py:167\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(e)\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/validators/data/utilities/decorators.py:48\u001b[0m, in \u001b[0;36mdatatype_validator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: file size is less than 1e-05 megabytes (current minimum size allowable) or greater than 3.000001 megabytes (current maximum size allowable) - input_files/too_long.mp3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/converters/utilities/decorators.py:85\u001b[0m, in \u001b[0;36mdatatype_converter_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/system_builder/utilities/decorators.py:65\u001b[0m, in \u001b[0;36mkwargs_checker.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected keyword argument(s) for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(unexpected_args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/modules/utilities/decorators.py:52\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/validators/utilities/decorators.py:29\u001b[0m, in \u001b[0;36mtype_check_inputs.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: file size is less than 1e-05 megabytes (current minimum size allowable) or greater than 3.000001 megabytes (current maximum size allowable) - input_files/too_long.mp3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m test_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoo_long.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# process the file\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_file_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mexpire_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# have the output expire in 3 minutes\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmodules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# purposefully placing modules={}, they are hydrated in as necessary, see printout \u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlocal_save_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_directory\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# save the output to the output directory\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/system_builder/functions/checkin.py:82\u001b[0m, in \u001b[0;36mcheck_init_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     81\u001b[0m     check_init(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/modular_experiments/../krixik/utilities/converters/utilities/decorators.py:87\u001b[0m, in \u001b[0;36mdatatype_converter_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(e)\n",
      "\u001b[0;31mValueError\u001b[0m: file size is less than 1e-05 megabytes (current minimum size allowable) or greater than 3.000001 megabytes (current maximum size allowable) - input_files/too_long.mp3"
     ]
    }
   ],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# create a few modules\n",
    "module_1 = Module(name=\"transcribe\")\n",
    "module_2 = Module(name=\"translate\")\n",
    "module_3 = Module(name=\"text-embedder\")\n",
    "module_4 = Module(name=\"vector-search\")\n",
    "\n",
    "custom = CreatePipeline(name='my-fancy-transcribe-pipeline', \n",
    "                               module_chain=[module_1, module_2, module_3, module_4])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config - we'll do below)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)\n",
    "\n",
    "# define a test file in your input_files directory\n",
    "test_file = 'too_long.mp3'\n",
    "\n",
    "# process the file\n",
    "output = pipeline.process(local_file_path = input_directory + \"/\" + test_file,\n",
    "                             expire_time=60*3, # have the output expire in 3 minutes\n",
    "                             modules={},  # purposefully placing modules={}, they are hydrated in as necessary, see printout \n",
    "                             local_save_directory=output_directory)  # save the output to the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"8724acaf-1a98-4ce2-97cd-3d069c9be110\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"408bf0fe-0d90-4f6e-bd9e-c4cd042526c1\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_whdafsdhon.mp3\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 1,\n",
      "        \"created_at\": \"2024-04-13 21:58:03\",\n",
      "        \"last_updated\": \"2024-04-13 21:58:03\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"Cada vez que uso el trmino Latinx hay una rabia palpable que llena mis secciones de comentarios que simplemente no lo entiendo Todava puedes usar la palabra Latino. Todava me identifico como Latino todo el tiempo\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.296\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = pipeline.vector_search(query=\"ellos importan y tu no\", \n",
    "                                   symbolic_directory_paths=['/*'])\n",
    "\n",
    "json_print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: hydrated input modules: {'ocr': {'model': 'tesseract-en', 'params': {}}, 'json-to-txt': {'model': 'base', 'params': {}}, 'parser': {'model': 'fixed', 'params': {'chunk_size': 10, 'overlap_size': 2}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-search': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_ndvtwtdhsk.png\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 180 seconds, at Sat Apr 13 15:03:45 2024 UTC\n",
      "INFO: my-fancy-ocr-pipeline file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: b8b5cac2-f4b3-c6f0-77ab-39dca2b16262\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 5) - ocr processing complete.\n",
      "SUCCESS: module 2 (of 5) - json-to-txt processing complete.\n",
      "SUCCESS: module 3 (of 5) - parser processing complete.\n",
      "SUCCESS: module 4 (of 5) - text-embedder processing complete.\n",
      "SUCCESS: module 5 (of 5) - vector-search processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# one more example of a custom pipeline\n",
    "module_1 = Module(name=\"ocr\")\n",
    "module_2 = Module(name=\"json-to-txt\")\n",
    "module_3 = Module(name=\"parser\")\n",
    "module_4 = Module(name=\"text-embedder\")\n",
    "module_5 = Module(name=\"vector-search\")\n",
    "\n",
    "custom = CreatePipeline(name='my-fancy-ocr-pipeline', \n",
    "                               module_chain=[module_1, module_2, module_3, module_4, module_5])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config - we'll do below)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)\n",
    "\n",
    "# define a test file in your input_files directory\n",
    "test_file = 'seal.png'\n",
    "\n",
    "# process the file\n",
    "output = pipeline.process(local_file_path = input_directory + \"/\" + test_file,\n",
    "                             expire_time=60*3, # have the output expire in 3 minutes\n",
    "                             modules={},  # purposefully placing modules={}, they are hydrated in as necessary, see printout \n",
    "                             local_save_directory=output_directory)  # save the output to the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"ab63ff1d-2bb3-410e-82fe-67ae20a053f4\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"8018029e-e6db-4a13-88cc-096763ace678\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_ndvtwtdhsk.png\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 14,\n",
      "        \"created_at\": \"2024-04-13 22:00:48\",\n",
      "        \"last_updated\": \"2024-04-13 22:00:48\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"relief from the heat, and at dawn a hot gust\",\n",
      "          \"line_numbers\": [\n",
      "            3\n",
      "          ],\n",
      "          \"distance\": 0.311\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"hot gust of wind blows across the colorless sea. The\",\n",
      "          \"line_numbers\": [\n",
      "            3,\n",
      "            4\n",
      "          ],\n",
      "          \"distance\": 0.343\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"horses stir, stretching their parched muzzles towards the sea. They\",\n",
      "          \"line_numbers\": [\n",
      "            11,\n",
      "            12\n",
      "          ],\n",
      "          \"distance\": 0.389\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"The Seventh Seal The night had brought little relief from\",\n",
      "          \"line_numbers\": [\n",
      "            1,\n",
      "            3\n",
      "          ],\n",
      "          \"distance\": 0.398\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"throat. At the sudden gust of wind, the horses stir,\",\n",
      "          \"line_numbers\": [\n",
      "            10,\n",
      "            11\n",
      "          ],\n",
      "          \"distance\": 0.401\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = pipeline.vector_search(query=\"some respite from the temperature\", \n",
    "                                   symbolic_directory_paths=['/*'])\n",
    "\n",
    "json_print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more examples\n",
    "\n",
    "Here are some more examples I've tested manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_module_pipeline_examples = [\n",
    "    {\n",
    "        \"name\": \"caption-keyword-search\",\n",
    "        \"module_chain\": [\"caption\", \"json-to-txt\", \"keyword-search\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"caption-vector-search\",\n",
    "        \"module_chain\": [\n",
    "            \"caption\",\n",
    "            \"json-to-txt\",\n",
    "            \"parser\",\n",
    "            \"text-embedder\",\n",
    "            \"vector-search\",\n",
    "        ],\n",
    "    },\n",
    "    {\"name\": \"txt-keyword-search\", \"module_chain\": [\"json-to-txt\", \"keyword-search\"]},\n",
    "    {\n",
    "        \"name\": \"ocr-vector-search\",\n",
    "        \"module_chain\": [\n",
    "            \"ocr\",\n",
    "            \"json-to-txt\",\n",
    "            \"parser\",\n",
    "            \"text-embedder\",\n",
    "            \"vector-search\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ocr-keyword-search\",\n",
    "        \"module_chain\": [\"ocr\", \"json-to-txt\", \"keyword-search\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ocr-sentiment\",\n",
    "        \"module_chain\": [\"ocr\", \"json-to-txt\", \"parser\", \"sentiment\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"standard-vector-search\",\n",
    "        \"module_chain\": [\"parser\", \"text-embedder\", \"vector-search\"],\n",
    "    },\n",
    "    {\"name\": \"summarize-sentiment\", \"module_chain\": [\"summarize\", \"sentiment\"]},\n",
    "    {\n",
    "        \"name\": \"summarize-vector-search\",\n",
    "        \"module_chain\": [\n",
    "            \"summarize\",\n",
    "            \"json-to-txt\",\n",
    "            \"parser\",\n",
    "            \"text-embedder\",\n",
    "            \"vector-search\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"summarize-keyword-search\",\n",
    "        \"module_chain\": [\"summarize\", \"json-to-txt\", \"keyword-search\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"transcribe-vector-search\",\n",
    "        \"module_chain\": [\"transcribe\", \"text-embedder\", \"vector-search\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"transcribe-keyword-search\",\n",
    "        \"module_chain\": [\"transcribe\", \"json-to-txt\", \"keyword-search\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"transcribe-translate-vector-search\",\n",
    "        \"module_chain\": [\"transcribe\", \"translate\", \"text-embedder\", \"vector-search\"],\n",
    "    },\n",
    "    {\"name\": \"transcribe-summarize\", \"module_chain\": [\"transcribe\", \"summarize\"]},\n",
    "    {\"name\": \"transcribe-sentiment\", \"module_chain\": [\"transcribe\", \"sentiment\"]},\n",
    "    {\n",
    "        \"name\": \"translate-vector-search\",\n",
    "        \"module_chain\": [\"translate\", \"text-embedder\", \"vector-search\"],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"translate-keyword-search\",\n",
    "        \"module_chain\": [\"translate\", \"json-to-txt\", \"keyword-search\"],\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
