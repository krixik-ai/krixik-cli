{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example summary\n",
    "\n",
    "Description: make your documents searchable in any language\n",
    "\n",
    "Business use cases:\n",
    "\n",
    "- make documents searchable (in any language)\n",
    "- create searchable summaries of documents (in any language)\n",
    "\n",
    "Pipelines described:\n",
    "\n",
    "- parser --> text-embedder --> vector-search\n",
    "\n",
    "- translate --> json-to-txt --> parser --> text-embedder --> vector-search\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boilerplate setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "TEST_DUMMY_API_KEY = os.getenv('TEST_DUMMY_API_KEY_DEV')\n",
    "TEST_DUMMY_API_URL = os.getenv('TEST_DUMMY_API_URL_DEV')\n",
    "\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = TEST_DUMMY_API_KEY, \n",
    "            api_url = TEST_DUMMY_API_URL)\n",
    "\n",
    "import json\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "    \n",
    "# define directory for input files \n",
    "input_directory = 'input_files/'\n",
    "\n",
    "# define directory for output files\n",
    "output_directory = 'output_files'\n",
    "\n",
    "# define directory for pipeline_configs\n",
    "pipeline_configs_directory = 'pipeline_configs'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(name=\"parser\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='parser-pipeline-1', \n",
    "                        module_chain=[module_1])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: hydrated input modules: {'parser': {'model': 'sentence', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_iwxijryfod.txt\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 300 seconds, at Thu Apr 25 17:53:30 2024 UTC\n",
      "INFO: parser-pipeline-1 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: bc3e5081-02ea-039c-e776-f4bbd163cffe\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 1) - parser processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# define path to an input file\n",
    "test_file = \"1984_full.txt\"\n",
    "\n",
    "# process for search\n",
    "output = pipeline.process(local_file_path = input_directory + test_file,\n",
    "                          expire_time=60*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(name=\"transcribe\")\n",
    "module_2 = Module(name=\"translate\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='translate-pipeline-1', \n",
    "                        module_chain=[module_1, module_2])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted input_files/Interesting Facts About Colombia.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpowejric2/krixik_converted_version_Interesting Facts About Colombia.mp3\n",
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}, 'translate': {'model': 'opus-mt-en-es', 'params': {}}}\n",
      "INFO: lower casing file_name Interesting Facts About Colombia.mp4 to interesting facts about colombia.mp4\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 300 seconds, at Thu Apr 25 11:10:43 2024 UTC\n",
      "INFO: translate-pipeline-1 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: 277349ac-f13a-9d04-5bed-efb5f4f69dd0\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 2) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 2) - translate processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "test_file = 'Interesting Facts About Colombia.mp4'\n",
    "# test_file = \"valid.json\"\n",
    "\n",
    "# process for search\n",
    "output = pipeline.process(local_file_path = input_directory + test_file,\n",
    "                          file_name = test_file,\n",
    "                          expire_time=60*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "TEST_DUMMY_API_KEY = os.getenv('TEST_DUMMY_API_KEY_DEV')\n",
    "TEST_DUMMY_API_URL = os.getenv('TEST_DUMMY_API_URL_DEV')\n",
    "\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = TEST_DUMMY_API_KEY, \n",
    "            api_url = TEST_DUMMY_API_URL)\n",
    "\n",
    "import json\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "    \n",
    "# define directory for input files \n",
    "input_directory = 'input_data/'\n",
    "\n",
    "# define directory for output files\n",
    "output_directory = 'output_data'\n",
    "\n",
    "# define directory for pipeline_configs\n",
    "pipeline_configs_directory = 'pipeline_configs'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  vector search pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by building a pipeline for semantic search in english.  \n",
    "\n",
    "This will consist of a parser, embedder, and vector search module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(module_type=\"parser\")\n",
    "module_2 = Module(module_type=\"text-embedder\")\n",
    "module_3 = Module(module_type=\"vector-db\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='vector-pipeline-1', \n",
    "                        module_chain=[module_1, module_2, module_3])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to use this pipeline since most modules have options - models and parameters- you can set when using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the pipeline defined we can process a file for search.\n",
    "\n",
    "Here we process with all cli verbose signals on, and wait for the output to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 9 0 (offset 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Converting pdf to text...\n",
      "SUCCESS: File conversion complete with pydf, result saved to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpf7iy49ho/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted input_data/chapter_1_short.pdf to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpf7iy49ho/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: hydrated input modules: {'parser': {'model': 'sentence', 'params': {}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-db': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_drkstwiacu.txt\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 300 seconds, at Sun Apr 28 13:56:45 2024 UTC\n",
      "INFO: vector-pipeline-1 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: 4a3c50c8-1ee7-8ab2-db06-a98faf06f55d\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 3) - parser processing complete.\n",
      "SUCCESS: module 2 (of 3) - text-embedder processing complete.\n",
      "SUCCESS: module 3 (of 3) - vector-db processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# define path to an input file\n",
    "test_file = \"chapter_1_short.pdf\"\n",
    "\n",
    "# process for search\n",
    "output = pipeline.process(local_file_path = input_directory + test_file,\n",
    "                          expire_time=60*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output contains metainformation about the file we just processed - including its file_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"vector-pipeline-1\",\n",
      "  \"request_id\": \"7d0b4339-7b45-43d8-9190-6bbc1437a921\",\n",
      "  \"file_id\": \"e014905c-55e8-404a-96e2-f39763acb1c2\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id e014905c-55e8-404a-96e2-f39763acb1c2.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"/Users/jeremywatt/Desktop/krixik-cli/examples/e014905c-55e8-404a-96e2-f39763acb1c2.faiss\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the file processed we can now search it semantically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_code': 200,\n",
       " 'request_id': 'de72c9c2-c28c-4645-b83e-bae604940c71',\n",
       " 'message': 'Successfully queried 1 user file.',\n",
       " 'warnings': [],\n",
       " 'items': [{'file_id': 'e014905c-55e8-404a-96e2-f39763acb1c2',\n",
       "   'file_metadata': {'file_name': 'krixik_generated_file_name_drkstwiacu.txt',\n",
       "    'symbolic_directory_path': '/etc',\n",
       "    'file_tags': [],\n",
       "    'num_vectors': 13,\n",
       "    'created_at': '2024-04-28 20:51:48',\n",
       "    'last_updated': '2024-04-28 20:51:48'},\n",
       "   'search_results': [{'snippet': 'While still a young dis-\\ncipline with much more awaiting discovery than is currently known, today\\nmachine learning can be used to teach computers to perform a wide array\\nof useful tasks including automatic detection of objects in images (a crucial\\ncomponent of driver-assisted and self-driving cars), speech recognition (which\\npowers voice command technology), knowledge discovery in the medical sci-\\nences (used to improve our understanding of complex diseases), and predictive\\nanalytics (leveraged for sales and economic forecasting), to just name a few.',\n",
       "     'line_numbers': [6, 7, 8, 9, 10, 11, 12, 13],\n",
       "     'distance': 0.371},\n",
       "    {'snippet': '1Introduction to Machine\\nLearning\\n1.1 Introduction\\nMachine learning is a uniﬁed algorithmic framework designed to identify com-\\nputational models that accurately describe empirical data and the phenomena\\nunderlying it, with little or no human involvement.',\n",
       "     'line_numbers': [1, 2, 3, 4, 5, 6],\n",
       "     'distance': 0.399},\n",
       "    {'snippet': 'In this chapter we give a high-level introduction to the ﬁeld of machine\\nlearning as well as the contents of this textbook.',\n",
       "     'line_numbers': [14, 15],\n",
       "     'distance': 0.41},\n",
       "    {'snippet': 'This will allow us to informally describe the\\nterminology and procedures involved in solving the typical machine learning\\nproblem.',\n",
       "     'line_numbers': [20, 21, 22],\n",
       "     'distance': 0.432},\n",
       "    {'snippet': '1.2 Distinguishing Cats from Dogs: a Machine Learning\\nApproach\\nTo get a big-picture sense of how machine learning works, we begin by dis-\\ncussing a toy problem: teaching a computer how to distinguish between pic-\\ntures of cats from those with dogs .',\n",
       "     'line_numbers': [16, 17, 18, 19, 20],\n",
       "     'distance': 0.438}]}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search the file we just processed semantically\n",
    "pipeline.semantic_search(query=\"one with the machines\",\n",
    "                         file_ids=[output[\"file_id\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also upload files without all the verbose output, and without waiting for each file to finish processing.  \n",
    "\n",
    "We can also set a `file_name` so that results are easier to understand visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process more files but don't wait \n",
    "more_test_files = [\"1984_full.txt\", \"slides.pptx\"]\n",
    "\n",
    "for test_file in more_test_files:\n",
    "    output = pipeline.process(local_file_path = input_directory + test_file,\n",
    "                              file_name=test_file,\n",
    "                              expire_time=60*5,\n",
    "                              wait_for_process=False,\n",
    "                              verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"fa458d98-c160-4be7-a581-a314822e0061\",\n",
      "  \"message\": \"Successfully queried 3 user files.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"899235b5-7202-4e43-90dd-d26601911efa\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"slides.pptx\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 16,\n",
      "        \"created_at\": \"2024-04-18 19:52:01\",\n",
      "        \"last_updated\": \"2024-04-18 19:52:01\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"a sample slidewith some text in itMancala infra overviewCost, Problems,\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.483\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"negligible data transfer in / outapproximate base user - $0.50DynamoDB\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.495\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"file_id\": \"05e1792b-e6b5-4beb-91fb-3593d350b2b6\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"1984_full.txt\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 12385,\n",
      "        \"created_at\": \"2024-04-18 19:51:59\",\n",
      "        \"last_updated\": \"2024-04-18 19:51:59\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"I'll tell you every word of it. HE'S the one\",\n",
      "          \"line_numbers\": [\n",
      "            7734\n",
      "          ],\n",
      "          \"distance\": 0.266\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"like that. He's ever so good with his hands, Tom\",\n",
      "          \"line_numbers\": [\n",
      "            646\n",
      "          ],\n",
      "          \"distance\": 0.278\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"file_id\": \"494af12c-9d8a-4621-ad62-cbbf55282d2c\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"chapter_1_short.pdf\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 43,\n",
      "        \"created_at\": \"2024-04-18 19:49:45\",\n",
      "        \"last_updated\": \"2024-04-18 19:49:45\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"Dogs: a Machine Learning Approach To get a big-picture sense\",\n",
      "          \"line_numbers\": [\n",
      "            16,\n",
      "            17,\n",
      "            18\n",
      "          ],\n",
      "          \"distance\": 0.349\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"currently known, today machine learning can be used to teach\",\n",
      "          \"line_numbers\": [\n",
      "            7,\n",
      "            8\n",
      "          ],\n",
      "          \"distance\": 0.353\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = pipeline.vector_search(query = 'he loves the machine',\n",
    "                                symbolic_directory_paths=['/*'],\n",
    "                                k=2)\n",
    "\n",
    "json_print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### translated semantic search\n",
    "\n",
    "What if we had users that wanted to examine our text in another language?  \n",
    "\n",
    "Lets insert a `translate` module in our pipeline so that users can query in spanish instead of english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(name=\"translate\")\n",
    "module_2 = Module(name=\"json-to-txt\")\n",
    "module_3 = Module(name=\"parser\")\n",
    "module_4 = Module(name=\"text-embedder\")\n",
    "module_5 = Module(name=\"vector-search\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='vector-pipeline-2', \n",
    "                        module_chain=[module_1, module_2, module_3, module_4, module_5])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was a bright cold day in April, and the clocks were striking thirteen.',\n",
       " 'Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.',\n",
       " 'The hallway smelt of boiled cabbage and old rag mats.',\n",
       " 'At one end of it a\\ncoloured poster, too large for indoor display, had been tacked to the wall.',\n",
       " 'It depicted simply an enormous face, more than a metre wide: the face of a\\nman of about forty-five, with a heavy black moustache and ruggedly handsome\\nfeatures.',\n",
       " 'Winston made for the stairs.',\n",
       " 'It was no use trying the lift.',\n",
       " 'Even\\nat the best of times it was seldom working, and at present the electric\\ncurrent was cut off during daylight hours.',\n",
       " 'It was part of the economy drive\\nin preparation for Hate Week.',\n",
       " 'The flat was seven flights up, and Winston,\\nwho was thirty-nine and had a varicose ulcer above his right ankle, went\\nslowly, resting several times on the way.',\n",
       " 'On each landing, opposite the\\nlift-shaft, the poster with the enormous face gazed from the wall.',\n",
       " 'It was\\none of those pictures which are so contrived that the eyes follow you about\\nwhen you move.',\n",
       " 'BIG BROTHER IS WATCHING YOU, the caption beneath it ran.',\n",
       " 'Inside the flat a fruity voice was reading out a list of figures which had\\nsomething to do with the production of pig-iron.',\n",
       " 'The voice came from an\\noblong metal plaque like a dulled mirror which formed part of the surface\\nof the right-hand wall.',\n",
       " 'Winston turned a switch and the voice sank\\nsomewhat, though the words were still distinguishable.',\n",
       " 'The instrument\\n(the telescreen, it was called) could be dimmed, but there was no way of\\nshutting it off completely.',\n",
       " 'He moved over to the window: a smallish, frail\\nfigure, the meagreness of his body merely emphasized by the blue overalls\\nwhich were the uniform of the party.',\n",
       " 'His hair was very fair, his face\\nnaturally sanguine, his skin roughened by coarse soap and blunt razor\\nblades and the cold of the winter that had just ended.',\n",
       " 'Outside, even through the shut window-pane, the world looked cold.',\n",
       " 'Down in\\nthe street little eddies of wind were whirling dust and torn paper into\\nspirals, and though the sun was shining and the sky a harsh blue, there\\nseemed to be no colour in anything, except the posters that were plastered\\neverywhere.',\n",
       " \"The black-moustachio'd face gazed down from every commanding\\ncorner.\",\n",
       " 'There was one on the house-front immediately opposite.',\n",
       " \"BIG BROTHER\\nIS WATCHING YOU, the caption said, while the dark eyes looked deep into\\nWinston's own.\",\n",
       " 'Down at street level another poster, torn at one corner,\\nflapped fitfully in the wind, alternately covering and uncovering the\\nsingle word INGSOC.',\n",
       " 'In the far distance a helicopter skimmed down between\\nthe roofs, hovered for an instant like a bluebottle, and darted away again\\nwith a curving flight.',\n",
       " \"It was the police patrol, snooping into people's\\nwindows.\",\n",
       " 'The patrols did not matter, however.',\n",
       " 'Only the Thought Police\\nmattered.',\n",
       " \"Behind Winston's back the voice from the telescreen was still babbling away\\nabout pig-iron and the overfulfilment of the Ninth Three-Year Plan.\",\n",
       " 'The\\ntelescreen received and transmitted simultaneously.',\n",
       " 'Any sound that Winston\\nmade, above the level of a very low whisper, would be picked up by it,\\nmoreover, so long as he remained within the field of vision which the metal\\nplaque commanded, he could be seen as well as heard.',\n",
       " 'There was of course\\nno way of knowing whether you were being watched at any given moment.',\n",
       " 'How\\noften, or on what system, the Thought Police plugged in on any individual\\nwire was guesswork.',\n",
       " 'It was even conceivable that they watched everybody all\\nthe time.',\n",
       " 'But at any rate they could plug in your wire whenever they wanted\\nto.',\n",
       " 'You had to live--did live, from habit that became instinct--in the\\nassumption that every sound you made was overheard, and, except in\\ndarkness, every movement scrutinized.',\n",
       " 'Winston kept his back turned to the telescreen.',\n",
       " 'It was safer; though, as he\\nwell knew, even a back can be revealing.',\n",
       " 'A kilometre away the Ministry of\\nTruth, his place of work, towered vast and white above the grimy landscape.',\n",
       " 'This, he thought with a sort of vague distaste--this was London, chief\\ncity of Airstrip One, itself the third most populous of the provinces of\\nOceania.',\n",
       " 'He tried to squeeze out some childhood memory that should tell him\\nwhether London had always been quite like this.',\n",
       " 'Were there always these\\nvistas of rotting nineteenth-century houses, their sides shored up with\\nbaulks of timber, their windows patched with cardboard and their roofs\\nwith corrugated iron, their crazy garden walls sagging in all directions?',\n",
       " 'And the bombed sites where the plaster dust swirled in the air and the\\nwillow-herb straggled over the heaps of rubble; and the places where the\\nbombs had cleared a larger patch and there had sprung up sordid colonies\\nof wooden dwellings like chicken-houses?',\n",
       " 'But it was no use, he could not\\nremember: nothing remained of his childhood except a series of bright-lit\\ntableaux occurring against no background and mostly unintelligible.',\n",
       " 'The Ministry of Truth--Minitrue, in Newspeak [Newspeak was the official\\nlanguage of Oceania.',\n",
       " 'For an account of its structure and etymology see\\nAppendix.]',\n",
       " '--was startlingly different from any other object in sight.',\n",
       " 'It\\nwas an enormous pyramidal structure of glittering white concrete, soaring\\nup, terrace after terrace, 300 metres into the air.',\n",
       " 'From where Winston\\nstood it was just possible to read, picked out on its white face in\\nelegant lettering, the three slogans of the Party:\\n\\n\\n  WAR IS PEACE\\n  FREEDOM IS SLAVERY\\n  IGNORANCE IS STRENGTH']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: hydrated input modules: {'translate': {'model': 'opus-mt-en-es', 'params': {}}, 'json-to-txt': {'model': 'base', 'params': {}}, 'parser': {'model': 'fixed', 'params': {'chunk_size': 10, 'overlap_size': 2}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-search': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 600 seconds, at Thu Apr 18 13:36:58 2024 UTC\n",
      "INFO: vector-pipeline-2 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: 70928fc8-248b-f2d9-beb4-0888e3c58d1b\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 5) - translate processing complete.\n",
      "SUCCESS: module 2 (of 5) - json-to-txt processing complete.\n",
      "SUCCESS: module 3 (of 5) - parser processing complete.\n",
      "SUCCESS: module 4 (of 5) - text-embedder processing complete.\n",
      "SUCCESS: module 5 (of 5) - vector-search processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "test_file = \"1984_short.txt\"\n",
    "\n",
    "### we need to add a parser that splits text into sentences - this is the local work around ###\n",
    "with open(input_directory + test_file, \"r\") as readfile:\n",
    "    text = readfile.read()\n",
    "\n",
    "import nltk\n",
    "sent_text = nltk.sent_tokenize(text)\n",
    "\n",
    "with open(input_directory + \"1984_short.json\", \"w\") as outfile:\n",
    "    json.dump([{\"snippet\": t} for t in sent_text], outfile)\n",
    "#### end local work around ####\n",
    "    \n",
    "output = pipeline.process(local_file_path = input_directory + \"1984_short.json\",\n",
    "                          file_name=\"1984_short.json\",\n",
    "                          expire_time=60*10,\n",
    "                          modules={\"translate\":{\"model\":\"opus-mt-en-es\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_code': 200,\n",
       " 'request_id': 'a7bb6fbc-fde9-4201-b86d-7596cf539156',\n",
       " 'message': 'Successfully queried 1 user file.',\n",
       " 'warnings': [],\n",
       " 'items': [{'file_id': '2a849b9c-6b06-476a-853d-fd74c57aadde',\n",
       "   'file_metadata': {'file_name': '1984_short.json',\n",
       "    'symbolic_directory_path': '/etc',\n",
       "    'file_tags': [],\n",
       "    'num_vectors': 128,\n",
       "    'created_at': '2024-04-18 20:26:58',\n",
       "    'last_updated': '2024-04-18 20:26:58'},\n",
       "   'search_results': [{'snippet': 'hermano grande te est mirando, el pie de foto debajo',\n",
       "     'line_numbers': [13],\n",
       "     'distance': 0.24},\n",
       "    {'snippet': 'todo el mundo todo el tiempo. Pero, en cualquier caso,',\n",
       "     'line_numbers': [35, 36],\n",
       "     'distance': 0.241}]}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.vector_search(query = 'te está mirando',\n",
    "                        symbolic_directory_paths=['/*'],\n",
    "                        k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keyword search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also process text for keyword search by using the `keyword-search` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(name=\"keyword-search\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='simple-keyword-search', \n",
    "                        module_chain=[module_1])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Converting pdf to text...\n",
      "SUCCESS: File conversion complete with pydf, result saved to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmp0t_ew036/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted input_files/chapter_1_short.pdf to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmp0t_ew036/krixik_converted_version_chapter_1_short.txt\n",
      "INFO: hydrated input modules: {'keyword-search': {'model': 'base', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 300 seconds, at Thu Apr 18 11:21:35 2024 UTC\n",
      "INFO: simple-keyword-search file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: 3410d296-9e26-9fd4-627c-5ec5269340df\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 1) - keyword-search processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# define path to an input file\n",
    "test_file = \"chapter_1_short.pdf\"\n",
    "\n",
    "# process for search\n",
    "output = pipeline.process(local_file_path = input_directory + test_file,\n",
    "                          file_name = test_file,\n",
    "                          expire_time=60*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"11c927d4-16da-421a-bef0-6e3d4c8e5f1b\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following words in the query are in the stop_words list and thus no results will be returned for them\": [\n",
      "        \"and\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"4666a8ae-ca8b-4934-b6d3-489d7f27b318\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"chapter_1_short.pdf\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 32,\n",
      "        \"created_at\": \"2024-04-18 18:16:37\",\n",
      "        \"last_updated\": \"2024-04-18 18:16:37\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"keyword\": \"cats\",\n",
      "          \"line_number\": 16,\n",
      "          \"keyword_number\": 3\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"dogs\",\n",
      "          \"line_number\": 16,\n",
      "          \"keyword_number\": 5\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"cats\",\n",
      "          \"line_number\": 20,\n",
      "          \"keyword_number\": 3\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"dogs\",\n",
      "          \"line_number\": 20,\n",
      "          \"keyword_number\": 7\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"cats\",\n",
      "          \"line_number\": 23,\n",
      "          \"keyword_number\": 13\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"dogs\",\n",
      "          \"line_number\": 24,\n",
      "          \"keyword_number\": 1\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"cats\",\n",
      "          \"line_number\": 28,\n",
      "          \"keyword_number\": 11\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"dogs\",\n",
      "          \"line_number\": 28,\n",
      "          \"keyword_number\": 13\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"cats\",\n",
      "          \"line_number\": 30,\n",
      "          \"keyword_number\": 15\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"dogs\",\n",
      "          \"line_number\": 31,\n",
      "          \"keyword_number\": 2\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"cats\",\n",
      "          \"line_number\": 32,\n",
      "          \"keyword_number\": 6\n",
      "        },\n",
      "        {\n",
      "          \"keyword\": \"dogs\",\n",
      "          \"line_number\": 32,\n",
      "          \"keyword_number\": 8\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = pipeline.keyword_search(symbolic_directory_paths=[\"/*\"], \n",
    "                                    query=\"cats and dogs\")\n",
    "json_print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
