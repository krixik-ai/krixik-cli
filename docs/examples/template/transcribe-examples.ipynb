{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# semantically searchable multi-lingual transcription pipeline\n",
    "\n",
    "This document details a modular pipeline that takes in an audio/video file, transcribes it, translates the transcription into a desired language, and makes the result semantically searchable.\n",
    "\n",
    "Such a pipeline could be used to make podcast conversations searchable in any language, and likewise notes from an audio/video meeting.\n",
    "\n",
    "\n",
    "Description: transcribe any audio/video and make it searchable in any language.\n",
    "\n",
    "Business use cases: \n",
    "\n",
    "    - make podcasts searchable in any language\n",
    "    - transcripts and automated summaries from meeting notes\n",
    "\n",
    "\n",
    "Pipelines described:\n",
    "\n",
    "- transcribe\n",
    "\n",
    "- transcribe --> json-to-txt --> parser --> text_embedder --> vector-search\n",
    "\n",
    "- transcribe --> translate --> json-to-txt --> parser --> text_embedder --> vector-search\n",
    "\n",
    "- transcribe --> summarize\n",
    "\n",
    "- transcribe --> sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "TEST_DUMMY_API_KEY = os.getenv('TEST_DUMMY_API_KEY_DEV')\n",
    "TEST_DUMMY_API_URL = os.getenv('TEST_DUMMY_API_URL_DEV')\n",
    "\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = TEST_DUMMY_API_KEY, \n",
    "            api_url = TEST_DUMMY_API_URL)\n",
    "\n",
    "import json\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "    \n",
    "# define directory for input files \n",
    "input_directory = 'input_files/'\n",
    "\n",
    "# define directory for output files\n",
    "output_directory = 'output_files'\n",
    "\n",
    "# define directory for pipeline_configs\n",
    "pipeline_configs_directory = 'pipeline_configs/'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(name=\"transcribe\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='transcribe-pipeline-1', \n",
    "                        module_chain=[module_1])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcribe-pipeline-1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted data/latinx_pride_short.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmprcecrni3/krixik_converted_version_latinx_pride_short.mp3\n",
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_cxtedywpgc.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 180 seconds, at Tue Apr  9 14:35:31 2024 UTC\n",
      "INFO: transcribe-pipeline-1 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: d6497aa8-c0f5-91dc-578e-b3808243ce71\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 1) - transcribe processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "test_file = \"latinx_pride_short.mp4\"\n",
    "output = pipeline.process(local_file_path = input_directory + test_file,\n",
    "                          expire_time=60*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once complete i can view its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"ed4fbf33-05b3-4a5e-8b91-88e27e1868fe\",\n",
      "  \"file_id\": \"6854e4ec-5146-4648-b7ff-d4f6d61d9c68\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 6854e4ec-5146-4648-b7ff-d4f6d61d9c68.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"transcript\": \" Every time I use the term Latinx there is a palpable rage that fills my comment sections that I just don't get it You can still use the word Latino. I still self identify as Latino all the time\",\n",
      "      \"timestamped_transcript\": [\n",
      "        {\n",
      "          \"id\": 0,\n",
      "          \"start\": 0.34,\n",
      "          \"end\": 6.36,\n",
      "          \"text\": \" Every time I use the term Latinx there is a palpable rage that fills my comment sections that I just don't get it\",\n",
      "          \"no_speech_prob\": 0.026368845254182816,\n",
      "          \"confidence\": 0.813,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"text\": \"Every\",\n",
      "              \"start\": 0.34,\n",
      "              \"end\": 0.58,\n",
      "              \"confidence\": 0.858\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"time\",\n",
      "              \"start\": 0.58,\n",
      "              \"end\": 0.82,\n",
      "              \"confidence\": 0.957\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"I\",\n",
      "              \"start\": 0.82,\n",
      "              \"end\": 0.94,\n",
      "              \"confidence\": 0.973\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"use\",\n",
      "              \"start\": 0.94,\n",
      "              \"end\": 1.1,\n",
      "              \"confidence\": 0.92\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"the\",\n",
      "              \"start\": 1.1,\n",
      "              \"end\": 1.22,\n",
      "              \"confidence\": 0.969\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"term\",\n",
      "              \"start\": 1.22,\n",
      "              \"end\": 1.42,\n",
      "              \"confidence\": 0.891\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"Latinx\",\n",
      "              \"start\": 1.42,\n",
      "              \"end\": 2.02,\n",
      "              \"confidence\": 0.612\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"there\",\n",
      "              \"start\": 2.02,\n",
      "              \"end\": 2.2,\n",
      "              \"confidence\": 0.462\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"is\",\n",
      "              \"start\": 2.2,\n",
      "              \"end\": 2.34,\n",
      "              \"confidence\": 0.957\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"a\",\n",
      "              \"start\": 2.34,\n",
      "              \"end\": 2.5,\n",
      "              \"confidence\": 0.98\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"palpable\",\n",
      "              \"start\": 2.5,\n",
      "              \"end\": 3.1,\n",
      "              \"confidence\": 0.936\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"rage\",\n",
      "              \"start\": 3.1,\n",
      "              \"end\": 3.58,\n",
      "              \"confidence\": 0.483\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"that\",\n",
      "              \"start\": 3.58,\n",
      "              \"end\": 3.82,\n",
      "              \"confidence\": 0.953\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"fills\",\n",
      "              \"start\": 3.82,\n",
      "              \"end\": 4.08,\n",
      "              \"confidence\": 0.965\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"my\",\n",
      "              \"start\": 4.08,\n",
      "              \"end\": 4.28,\n",
      "              \"confidence\": 0.984\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"comment\",\n",
      "              \"start\": 4.28,\n",
      "              \"end\": 4.62,\n",
      "              \"confidence\": 0.451\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"sections\",\n",
      "              \"start\": 4.62,\n",
      "              \"end\": 5.12,\n",
      "              \"confidence\": 0.886\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"that\",\n",
      "              \"start\": 5.12,\n",
      "              \"end\": 5.3,\n",
      "              \"confidence\": 0.414\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"I\",\n",
      "              \"start\": 5.3,\n",
      "              \"end\": 5.42,\n",
      "              \"confidence\": 0.899\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"just\",\n",
      "              \"start\": 5.42,\n",
      "              \"end\": 5.8,\n",
      "              \"confidence\": 0.982\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"don't\",\n",
      "              \"start\": 5.8,\n",
      "              \"end\": 6.08,\n",
      "              \"confidence\": 0.911\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"get\",\n",
      "              \"start\": 6.08,\n",
      "              \"end\": 6.2,\n",
      "              \"confidence\": 0.987\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"it\",\n",
      "              \"start\": 6.2,\n",
      "              \"end\": 6.36,\n",
      "              \"confidence\": 0.986\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"id\": 1,\n",
      "          \"start\": 6.66,\n",
      "          \"end\": 10.56,\n",
      "          \"text\": \" You can still use the word Latino. I still self identify as Latino all the time\",\n",
      "          \"no_speech_prob\": 0.026368845254182816,\n",
      "          \"confidence\": 0.886,\n",
      "          \"words\": [\n",
      "            {\n",
      "              \"text\": \"You\",\n",
      "              \"start\": 6.66,\n",
      "              \"end\": 6.88,\n",
      "              \"confidence\": 0.953\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"can\",\n",
      "              \"start\": 6.88,\n",
      "              \"end\": 7.08,\n",
      "              \"confidence\": 0.998\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"still\",\n",
      "              \"start\": 7.08,\n",
      "              \"end\": 7.26,\n",
      "              \"confidence\": 0.999\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"use\",\n",
      "              \"start\": 7.26,\n",
      "              \"end\": 7.5,\n",
      "              \"confidence\": 0.997\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"the\",\n",
      "              \"start\": 7.5,\n",
      "              \"end\": 7.62,\n",
      "              \"confidence\": 0.989\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"word\",\n",
      "              \"start\": 7.62,\n",
      "              \"end\": 7.74,\n",
      "              \"confidence\": 0.977\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"Latino.\",\n",
      "              \"start\": 7.74,\n",
      "              \"end\": 8.1,\n",
      "              \"confidence\": 0.481\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"I\",\n",
      "              \"start\": 8.24,\n",
      "              \"end\": 8.6,\n",
      "              \"confidence\": 0.987\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"still\",\n",
      "              \"start\": 8.6,\n",
      "              \"end\": 8.82,\n",
      "              \"confidence\": 0.989\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"self\",\n",
      "              \"start\": 8.82,\n",
      "              \"end\": 9.12,\n",
      "              \"confidence\": 0.768\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"identify\",\n",
      "              \"start\": 9.12,\n",
      "              \"end\": 9.46,\n",
      "              \"confidence\": 0.516\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"as\",\n",
      "              \"start\": 9.46,\n",
      "              \"end\": 9.76,\n",
      "              \"confidence\": 0.901\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"Latino\",\n",
      "              \"start\": 9.76,\n",
      "              \"end\": 10.06,\n",
      "              \"confidence\": 0.947\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"all\",\n",
      "              \"start\": 10.06,\n",
      "              \"end\": 10.22,\n",
      "              \"confidence\": 0.993\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"the\",\n",
      "              \"start\": 10.22,\n",
      "              \"end\": 10.38,\n",
      "              \"confidence\": 0.997\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"time\",\n",
      "              \"start\": 10.38,\n",
      "              \"end\": 10.56,\n",
      "              \"confidence\": 0.998\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even constructed pipelines are flexible.  \n",
    "\n",
    "Our current pipeline consists of one module - transcription - that has several model options.  \n",
    "\n",
    "We can view these below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### english searchable-transcripts\n",
    "\n",
    "Lets make our transcriptions searchable.\n",
    "\n",
    "We can simply add on modules embedding and search modules after transcribe, creating a new pipeline.\n",
    "\n",
    "This will make our transcripts searchable in english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(name=\"transcribe\")\n",
    "module_2 = Module(name=\"json-to-txt\")\n",
    "module_3 = Module(name=\"parser\")\n",
    "module_4 = Module(name=\"text-embedder\")\n",
    "module_5 = Module(name=\"vector-search\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='transcribe-pipeline-2', \n",
    "                        module_chain=[module_1, module_2, module_3, module_4, module_5])\n",
    "\n",
    "# save your config for later use (that way you don't need to re-build in python)\n",
    "custom.save(config_path=pipeline_configs_directory + 'transcribe-pipeline-2.yml')\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted data/latinx_pride_short.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmp8h0swv85/krixik_converted_version_latinx_pride_short.mp3\n",
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-search': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_vboarqcogg.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 180 seconds, at Tue Apr  9 15:15:41 2024 UTC\n",
      "INFO: transcribe-pipeline-2 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: 3dd7b005-5740-0783-45a2-cd681c37ea77\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 3) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 3) - text-embedder processing complete.\n",
      "SUCCESS: module 3 (of 3) - vector-search processing complete.\n",
      "SUCCESS: pipeline process complete.\n"
     ]
    }
   ],
   "source": [
    "test_file = \"latinx_pride_short.mp4\"\n",
    "output = pipeline.process(local_file_path = input_directory + test_file,\n",
    "                             expire_time=60*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now out transcript is (vector) searchable.\n",
    "\n",
    "Lets try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"60fabbda-5561-4941-9e32-17ff50645d51\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"4748b502-7a4a-4649-9906-30ce1cd845ea\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_vboarqcogg.mp3\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 1,\n",
      "        \"created_at\": \"2024-04-09 22:12:42\",\n",
      "        \"last_updated\": \"2024-04-09 22:12:42\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \" Every time I use the term Latinx there is a palpable rage that fills my comment sections that I just don't get it You can still use the word Latino. I still self identify as Latino all the time\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.482\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = pipeline.vector_search(query=\"they matter and you dont\", \n",
    "                                   symbolic_directory_paths=['/*'])\n",
    "\n",
    "json_print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (your-language-goes-here)-searchable-transcripts\n",
    "\n",
    "Perhaps our audience would like to view and search transcripts in another language - like spanish.\n",
    "\n",
    "We can easily adjust our pipeline to allow for this - by adding in a `translate` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(name=\"transcribe\")\n",
    "module_2 = Module(name=\"translate\")\n",
    "module_3 = Module(name=\"json-to-txt\")\n",
    "module_4 = Module(name=\"parser\")\n",
    "module_5 = Module(name=\"text-embedder\")\n",
    "module_6 = Module(name=\"vector-search\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='transcribe-pipeline-3', \n",
    "                        module_chain=[module_1, module_2, module_3, module_4, module_5, module_6])\n",
    "\n",
    "# save your config for later use (that way you don't need to re-build in python)\n",
    "custom.save(config_path=pipeline_configs_directory + 'transcribe-pipeline-3.yml')\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This single pipeline has quite a bit of flexibility baked into it.\n",
    "\n",
    "Most modules have several choices for models / parameters.\n",
    "\n",
    "For example, we can choose from various sized transcriber models, and translation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline': {'name': 'transcribe-pipeline-3',\n",
       "  'modules': [{'name': 'transcribe',\n",
       "    'models': [{'name': 'whisper-tiny'},\n",
       "     {'name': 'whisper-base'},\n",
       "     {'name': 'whisper-small'},\n",
       "     {'name': 'whisper-medium'},\n",
       "     {'name': 'whisper-large-v3'}],\n",
       "    'defaults': {'model': 'whisper-tiny'},\n",
       "    'input': {'type': 'audio', 'permitted_extensions': ['.mp3', '.mp4']},\n",
       "    'output': {'type': 'json'}},\n",
       "   {'name': 'translate',\n",
       "    'models': [{'name': 'opus-mt-de-en'},\n",
       "     {'name': 'opus-mt-en-es'},\n",
       "     {'name': 'opus-mt-es-en'},\n",
       "     {'name': 'opus-mt-en-fr'},\n",
       "     {'name': 'opus-mt-fr-en'},\n",
       "     {'name': 'opus-mt-it-en'},\n",
       "     {'name': 'opus-mt-zh-en'}],\n",
       "    'defaults': {'model': 'opus-mt-en-es'},\n",
       "    'input': {'type': 'json', 'permitted_extensions': ['.json']},\n",
       "    'output': {'type': 'json'}},\n",
       "   {'name': 'json-to-txt',\n",
       "    'models': [{'name': 'base'}],\n",
       "    'defaults': {'model': 'base'},\n",
       "    'input': {'type': 'json', 'permitted_extensions': ['.json']},\n",
       "    'output': {'type': 'text'}},\n",
       "   {'name': 'parser',\n",
       "    'models': [{'name': 'fixed',\n",
       "      'params': {'chunk_size': {'type': 'int'},\n",
       "       'overlap_size': {'type': 'int'}}}],\n",
       "    'defaults': {'model': 'fixed'},\n",
       "    'input': {'type': 'text',\n",
       "     'permitted_extensions': ['.txt', '.pdf', '.docx', '.pptx']},\n",
       "    'output': {'type': 'json'}},\n",
       "   {'name': 'text-embedder',\n",
       "    'models': [{'name': 'multi-qa-MiniLM-L6-cos-v1',\n",
       "      'params': {'quantize': {'type': 'bool'}}},\n",
       "     {'name': 'msmarco-distilbert-dot-v5',\n",
       "      'params': {'quantize': {'type': 'bool'}}},\n",
       "     {'name': 'all-MiniLM-L12-v2', 'params': {'quantize': {'type': 'bool'}}},\n",
       "     {'name': 'all-mpnet-base-v2', 'params': {'quantize': {'type': 'bool'}}},\n",
       "     {'name': 'all-MiniLM-L6-v2', 'params': {'quantize': {'type': 'bool'}}}],\n",
       "    'defaults': {'model': 'multi-qa-MiniLM-L6-cos-v1'},\n",
       "    'input': {'type': 'json', 'permitted_extensions': ['.json']},\n",
       "    'output': {'type': 'npy'}},\n",
       "   {'name': 'vector-search',\n",
       "    'models': [{'name': 'faiss'}],\n",
       "    'defaults': {'model': 'faiss'},\n",
       "    'input': {'type': 'npy', 'permitted_extensions': ['.npy']},\n",
       "    'output': {'type': 'faiss'}}]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted input_files/latinx_pride_short.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpw1iduw64/krixik_converted_version_latinx_pride_short.mp3\n",
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}, 'translate': {'model': 'opus-mt-en-es', 'params': {}}, 'json-to-txt': {'model': 'base', 'params': {}}, 'parser': {'model': 'fixed', 'params': {'chunk_size': 10, 'overlap_size': 2}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-search': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_gltnlkxpmh.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 180 seconds, at Wed Apr 24 12:47:57 2024 UTC\n",
      "INFO: transcribe-pipeline-3 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: 176ebdd0-27cb-db7d-4d38-1038ac744fef\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 6) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 6) - translate processing complete.\n",
      "SUCCESS: module 3 (of 6) - json-to-txt processing complete.\n",
      "SUCCESS: module 4 (of 6) - parser processing complete.\n",
      "SUCCESS: module 5 (of 6) - text-embedder processing complete.\n",
      "SUCCESS: module 6 (of 6) - vector-search processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "test_file = \"latinx_pride_short.mp4\"\n",
    "output = pipeline.process(local_file_path = input_directory + test_file,\n",
    "                          expire_time=60*3,\n",
    "                          modules={\"translate\": {\"model\": \"opus-mt-en-es\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can search our translated transcript - in the language it was translated into (here spanish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"5f897211-1206-4d7b-94d1-72536f547fd7\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"ccfc436f-efa3-45f7-837d-f18d396d10e4\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_vtwikwigjk.mp3\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 5,\n",
      "        \"created_at\": \"2024-04-18 18:34:58\",\n",
      "        \"last_updated\": \"2024-04-18 18:34:58\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"Cada vez que uso el trmino Latinx hay una rabia\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.271\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"comentarios que simplemente no lo entiendo Todava puedes usar la\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.283\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Latino todo el tiempo\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.296\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"usar la palabra Latino. Todava me identifico como Latino todo\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.322\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"una rabia palpable que llena mis secciones de comentarios que\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.338\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = pipeline.vector_search(query=\"ellos importan y tu no\", \n",
    "                                symbolic_directory_paths=['/*'])\n",
    "\n",
    "json_print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to re-use your pipeline without having to re-build it in python, just save your config.  You can reload it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize raw transcript output\n",
    "\n",
    "```transcribe --> summarize```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# create a few modules\n",
    "module_1 = Module(name=\"transcribe\")\n",
    "module_2 = Module(name=\"summarize\")\n",
    "\n",
    "pipeline = CreatePipeline(name='transcribe-pipeline-4', \n",
    "                               module_chain=[module_1, module_2])\n",
    "pipeline.save('pipeline_configs/transcribe-pipeline-4.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted data/latinx_pride_short.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpu8av3ehp/krixik_converted_version_latinx_pride_short.mp3\n",
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}, 'summarize': {'model': 'bart-large-cnn', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_vaikdghybu.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 180 seconds, at Tue Apr  9 15:42:48 2024 UTC\n",
      "INFO: transcribe-pipeline-4 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: 9aed893b-1b2d-a52f-877d-55c2a600213d\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 2) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 2) - summarize processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "my_pipeline = krixik.load_pipeline(config_path=\"pipeline_configs/transcribe-pipeline-4.yaml\")\n",
    "test_file_name = 'data/latinx_pride_short.mp4'\n",
    "\n",
    "output = my_pipeline.process(local_file_path = test_file_name,\n",
    "                             expire_time=60*3,\n",
    "                             modules={})  # purposefully placing modules={}, they are filled in as necessary, not needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"3fc540bb-7746-4c22-baf6-53c58dcba514\",\n",
      "  \"file_id\": \"6d3665bd-4a04-488f-baf3-c561dd74ca68\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 6d3665bd-4a04-488f-baf3-c561dd74ca68.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"summary\": \"Every time I use the term Latinx there is a palpable rage that fills my comment sections that I just don't get it You can still use the word Latino. I still self identify as Latino all the time.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use sentiment analysis on transcript output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# create a few modules\n",
    "module_1 = Module(name=\"transcribe\")\n",
    "module_2 = Module(name=\"sentiment\")\n",
    "\n",
    "pipeline = CreatePipeline(name='transcribe-pipeline-5', \n",
    "                               module_chain=[module_1, module_2])\n",
    "pipeline.save('pipeline_configs/transcribe-pipeline-5.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted data/latinx_pride_short.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmp9pf8jcm6/krixik_converted_version_latinx_pride_short.mp3\n",
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}, 'sentiment': {'model': 'distilbert-base-uncased-finetuned-sst-2-english', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_xgpovlhhvi.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 180 seconds, at Tue Apr  9 15:41:28 2024 UTC\n",
      "INFO: transcribe-pipeline-5 file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This file's process_id is: 98497c36-de15-3f2b-1d61-ac1b6b70c30f\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 2) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 2) - sentiment processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "my_pipeline = krixik.load_pipeline(config_path=\"pipeline_configs/transcribe-pipeline-5.yaml\")\n",
    "test_file_name = 'data/latinx_pride_short.mp4'\n",
    "\n",
    "output = my_pipeline.process(local_file_path = test_file_name,\n",
    "                             expire_time=60*3,\n",
    "                             modules={})  # purposefully placing modules={}, they are filled in as necessary, not needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"7469baa2-105a-4b0c-89eb-af53c0fa37c9\",\n",
      "  \"file_id\": \"0823ed91-a98c-4d38-a272-eff11e26deb7\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 0823ed91-a98c-4d38-a272-eff11e26deb7.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \" Every time I use the term Latinx there is a palpable rage that fills my comment sections that I just don't get it You can still use the word Latino. I still self identify as Latino all the time\",\n",
      "      \"positive\": 0.02,\n",
      "      \"negative\": 0.98,\n",
      "      \"neutral\": 0.0\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
