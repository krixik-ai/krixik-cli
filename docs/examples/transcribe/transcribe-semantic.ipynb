{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# semantically searchable transcription pipeline\n",
    "\n",
    "This document details a modular pipeline that takes in an audio/video file, transcribes it, and makes the result semantically searchable.\n",
    "\n",
    "To follow along with this demonstration be sure to initialize your krixik session with your api key and url as shown below. \n",
    "\n",
    "We illustrate loading these required secrets in via [python-dotenv](https://pypi.org/project/python-dotenv/), storing those secrets in a `.env` file.  This is always good practice for storing / loading secrets (e.g., doing so will reduce the chance you inadvertantly push secrets to a repo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../../')\n",
    "\n",
    "from docs.utilities.reset import reset_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small function prints dictionaries very nicely in notebooks / markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dictionaries / json nicely in notebooks / markdown\n",
    "import json\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A table of contents for the remainder of this document is shown below.\n",
    "\n",
    "\n",
    "- [pipeline setup](#pipeline-setup)\n",
    "- [processing a file](#processing-a-file)\n",
    "- [performing semantic search](#performing-semantic-search)\n",
    "- [saving the pipeline config for future use](#saving-the-pipeline-config-for-future-use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we setup a multi module pipeline to serve our intended purpose, which is to build a pipeline that will transcribe any audio/video and make it semantically searchable in any language.\n",
    "\n",
    "To do this we will use the following modules:\n",
    "\n",
    "- [`transcribe`](modules/transcribe.md): takes in audio/video input, outputs json of content transcription\n",
    "- [`json-to-txt`](modules/json-to-txt.md): takes in json of text snippets, merges into text file\n",
    "- [`parser`](modules/parser.md): takes in text, slices into (possibly overlapping) strings\n",
    "- [`text-embedder`](modules/text-embedder.md): takes in text snippets, creates vector representation of each outputing an npy file\n",
    "- [`vector-db`](modules/vector-db.md): takes in npy of vectors, outputs vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(module_type=\"transcribe\")\n",
    "module_2 = Module(module_type=\"json-to-txt\")\n",
    "module_3 = Module(module_type=\"parser\")\n",
    "module_4 = Module(module_type=\"text-embedder\")\n",
    "module_5 = Module(module_type=\"vector-db\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='transcribe-semantic-pipeline', \n",
    "                        module_chain=[module_1, module_2, module_3, module_4, module_5])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our `custom` pipeline built we now pass it, along with a test file, to our operator to process the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processing a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a path to a local input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file\n",
    "test_file = \"../../input_data/Interesting Facts About Colombia.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at this file before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../../input_data/Interesting Facts About Colombia.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine contents of input file\n",
    "from IPython.display import Video\n",
    "Video(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this run we will use the default models for the each module of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted ../../input_data/Interesting Facts About Colombia.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmpb5m88eea/krixik_converted_version_Interesting Facts About Colombia.mp3\n",
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}, 'json-to-txt': {'model': 'base', 'params': {}}, 'parser': {'model': 'sentence', 'params': {}}, 'text-embedder': {'model': 'multi-qa-MiniLM-L6-cos-v1', 'params': {'quantize': True}}, 'vector-db': {'model': 'faiss', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_tnzlfqdsly.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 300 seconds, at Mon Apr 29 16:02:50 2024 UTC\n",
      "INFO: transcribe-semantic-pipeline file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: e04aa020-3d5c-5391-531e-23c222c820cd\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 5) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 5) - json-to-txt processing complete.\n",
      "SUCCESS: module 3 (of 5) - parser processing complete.\n",
      "SUCCESS: module 4 (of 5) - text-embedder processing complete.\n",
      "SUCCESS: module 5 (of 5) - vector-db processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# test file\n",
    "test_file = \"../../input_data/Interesting Facts About Colombia.mp4\"\n",
    "\n",
    "# process test input\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  expire_time=60*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below.  Because the output of this particular pipeline is a database file, the process output is shown as null in the output.  The local address of the output file itself has been returned to the address noted in the `process_output_files` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"transcribe-semantic-pipeline\",\n",
      "  \"request_id\": \"37608ba0-db6e-44ef-b93e-7196616b3331\",\n",
      "  \"file_id\": \"e0024f60-9192-4e05-8bb3-a0a0423305ab\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id e0024f60-9192-4e05-8bb3-a0a0423305ab.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"/Users/jeremywatt/Desktop/krixik-cli/docs/examples/transcribe/e0024f60-9192-4e05-8bb3-a0a0423305ab.faiss\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "json_print(process_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performing semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our pipeline has `text-embedder` and `vector-db` modules we can semantically search the translated transcription, here in Spanish (since we processed our file with an English-Spanish model).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"d88bf437-a742-41c1-8b28-5981d5c44bcc\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"e0024f60-9192-4e05-8bb3-a0a0423305ab\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_file_name_tnzlfqdsly.mp3\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 41,\n",
      "        \"created_at\": \"2024-04-29 22:57:52\",\n",
      "        \"last_updated\": \"2024-04-29 22:57:52\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"Learn about Columbia.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.263\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"And I know coffee is really important when it comes to talking about Columbia, but you guys really don't know how important it is with its culture.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.287\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"You Columbia coffee right here.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.292\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Now interesting enough when it comes to the coffee in Columbia, believe it or not, it is not actually native to the country.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.298\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"So we all know Columbia is famous for its coffee, right?\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.306\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# semantically search translated transcription\n",
    "search_output = pipeline.semantic_search(query=\"lets talk about the country of Colombia\", \n",
    "                                         file_ids=[process_output[\"file_id\"]])\n",
    "\n",
    "json_print(search_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about the [`semantic_search` method here](system/semantic_search.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving the pipeline config for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the configuration of this pipeline using the `custom` object, and use it later direclty without building it again in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your config for later use (that way you don't need to re-build in python)\n",
    "custom.save(config_path='transcribe-semantic-pipeline.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See more about [saving and loading pipeline configuration files](LINNK GOES HERE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
