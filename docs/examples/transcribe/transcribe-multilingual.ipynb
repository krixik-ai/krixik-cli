{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multilingual transcription pipeline\n",
    "\n",
    "This document details a modular pipeline that takes in an audio/video file, transcribes it, and translates the transcription into a desired language.\n",
    "\n",
    "To follow along with this demonstration be sure to initialize your krixik session with your api key and url as shown below. \n",
    "\n",
    "We illustrate loading these required secrets in via [python-dotenv](https://pypi.org/project/python-dotenv/), storing those secrets in a `.env` file.  This is always good practice for storing / loading secrets (e.g., doing so will reduce the chance you inadvertantly push secrets to a repo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../../')\n",
    "\n",
    "from docs.utilities.reset import reset_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small function prints dictionaries very nicely in notebooks / markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dictionaries / json nicely in notebooks / markdown\n",
    "import json\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A table of contents for the remainder of this document is shown below.\n",
    "\n",
    "\n",
    "- [pipeline setup](#pipeline-setup)\n",
    "- [processing a file](#processing-a-file)\n",
    "- [saving the pipeline config for future use](#saving-the-pipeline-config-for-future-use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we setup a multi module pipeline to serve our intended purpose, which is to build a pipeline that will transcribe any audio/video and make it semantically searchable in any language.\n",
    "\n",
    "To do this we will use the following modules:\n",
    "\n",
    "- [`transcribe`](modules/transcribe.md): takes in audio/video input, outputs json of content transcription\n",
    "- [`translate`](modules/translate.md): takes in json of text snippets, outputs json of translated snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# select modules\n",
    "module_1 = Module(module_type=\"transcribe\")\n",
    "module_2 = Module(module_type=\"translate\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='transcribe-translate-pipeline', \n",
    "                        module_chain=[module_1, module_2])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our `custom` pipeline built we now pass it, along with a test file, to our operator to process the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processing a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a path to a local input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file\n",
    "test_file = \"../input_data/Interesting Facts About Colombia.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at this file before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../input_data/Interesting Facts About Colombia.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine contents of input file\n",
    "from IPython.display import Video\n",
    "Video(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input video content language content is English.  We will use the `opus-mt-en-es` model of the [`translate`](modules/translate.md) to translate the transcript of this video into Spanish.\n",
    "\n",
    "For this run we will use the default models for the remainder of the modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking that file size falls within acceptable parameters...\n",
      "INFO:...success!\n",
      "converted ../input_data/Interesting Facts About Colombia.mp4 to: /var/folders/k9/0vtmhf0s5h56gt15mkf07b1r0000gn/T/tmppaeads7s/krixik_converted_version_Interesting Facts About Colombia.mp3\n",
      "INFO: hydrated input modules: {'transcribe': {'model': 'whisper-tiny', 'params': {}}, 'translate': {'model': 'opus-mt-en-es', 'params': {}}}\n",
      "INFO: symbolic_directory_path was not set by user - setting to default of /etc\n",
      "INFO: file_name was not set by user - setting to random file name: krixik_generated_file_name_xqpbbvidoq.mp3\n",
      "INFO: wait_for_process is set to True.\n",
      "INFO: file will expire and be removed from you account in 300 seconds, at Mon Apr 29 15:12:17 2024 UTC\n",
      "INFO: transcribe-translate-pipeline file process and input processing started...\n",
      "INFO: metadata can be updated using the .update api.\n",
      "INFO: This process's request_id is: 2cbc5bbb-bc0e-a552-a439-61e25bdfa4cc\n",
      "INFO: File process and processing status:\n",
      "SUCCESS: module 1 (of 2) - transcribe processing complete.\n",
      "SUCCESS: module 2 (of 2) - translate processing complete.\n",
      "SUCCESS: pipeline process complete.\n",
      "SUCCESS: process output downloaded\n"
     ]
    }
   ],
   "source": [
    "# test file\n",
    "test_file = \"../../input_data/Interesting Facts About Colombia.mp4\"\n",
    "\n",
    "# process test input\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  expire_time=60*5,\n",
    "                                  modules={\"translate\": {\"model\": \"opus-mt-en-es\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below.  Because the output of this particular pipeline is a json file, the process output is shown as well.  The local address of the output file itself has been returned to the address noted in the `process_output_files` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"transcribe-translate-pipeline\",\n",
      "  \"request_id\": \"47c08992-bbe6-4d4a-83b6-abb51ed53c8b\",\n",
      "  \"file_id\": \"82713863-4978-4909-b7ae-c61617b33ee8\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 82713863-4978-4909-b7ae-c61617b33ee8.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"Ese es el episodio que mira al gran pas de Columbia. Miramos algunos hechos realmente bsicos. Es el nombre, un poco de su historia, el tipo de gente que vive all, el tamao de la tierra, y todo ese jazz. Pero en este video, vamos a entrar en un poco ms de una mirada detallada. Yo, qu est pasando chicos? Bienvenidos de nuevo a los hechos F2D. El canal donde miro las culturas y lugares de la gente. Mi nombre es Dave Wouple, y hoy vamos a ver ms en Columbia y nuestro video de la segunda parte de Columbia. Lo que me recuerda chicos, esto es parte de nuestra lista de Columbia. As que pngalo en el cuadro de descripcin a continuacin, y voy a hablar de eso ms en el vdeo. Pero si eres nuevo aqu, nete a m todos los lunes para aprender sobre nuevos pases de todo el mundo. Usted puede hacer eso pulsando que suscribirse y ese botn de notificacin de cinturn. Pero comencemos. Aprende sobre Columbia. As que todos sabemos que Columbia es famosa por su caf, verdad? S, claro. Lo s. Ustedes estn ah sentados, cinco dlares dicen que va a hablar de caf. Bueno, lo soy. As es, porque tengo mi camioneta. T caf de Columbia justo aqu. Boom anuncio. S. Entonces me estoy pagando por esto. Me importa. As que lo que podra no saber sobre el caf es s, usted probablemente ya sabe que un montn de empresas realmente lo compran. Starbucks compra caf de Columbia. Es como su lugar favorito para comprar caf. Y como para rendir homenaje a ese Starbucks cuando estn haciendo su tienda nmero 1.000 en 2016, decidieron, yo, vamos a ponerlo en Columbia. Y esto fue en la ciudad de Medelln, Columbia. Ahora bien, cuando se trata de caf en Columbia, son el tercer pas productor y exportador de caf ms grande del mundo. La cantidad de caf que se exporta desde Colombia equivale a unas 810.000 toneladas mtricas o aproximadamente 11,5 millones de bolsas. Sin embargo, aunque podra ser vencido por pases como Brasil, en realidad es el pas nmero uno o ms alto para producir y cultivar un tipo especfico de frijol conocido como el beka rabe. Y s que el caf es muy importante cuando se trata de hablar de Columbia, pero ustedes realmente no saben lo importante que es con su cultura. Es interesante el hecho de que en 2007, los principales lugares que equivalan a una zona de amortiguacin de aproximadamente 207.000 hectreas, que se denominan el paisaje cultural del caf, fueron considerados Patrimonio de la Humanidad por la UNESCO. Y tambin en 2007, la UE, la Unin Europea, otorg al caf colombiano una denominacin de origen protegida. Ahora lo suficientemente interesante cuando se trata del caf en Columbia, lo creas o no, en realidad no es nativo del pas. Viene de otro lugar, no es realmente una especie invasiva porque es muy bienvenida. Ahora usted tambin puede haber visto a este tipo en muchas marcas de caf colombianas diferentes. Ahora se llama Juan Valdez. Ahora algunas personas piensan que este tipo es realmente un verdadero granjero de caf, alguien acaba de dibujar.\"\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"/Users/jeremywatt/Desktop/krixik-cli/docs/examples/82713863-4978-4909-b7ae-c61617b33ee8.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "json_print(process_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving the pipeline config for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the configuration of this pipeline using the `custom` object, and use it later direclty without building it again in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your config for later use (that way you don't need to re-build in python)\n",
    "custom.save(config_path='transcribe-translate-semantic-pipeline.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See more about [saving and loading pipeline configuration files](LINNK GOES HERE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
