{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overview of krixik system apis\n",
    "\n",
    "In this document we use a small example to illustrate the usage of krixik system apis.  These are apis avaiilable with all pipelines built with krixik.\n",
    "\n",
    "To follow along with this demonstration be sure to initialize your krixik session with your api key and url as shown below. \n",
    "\n",
    "We illustrate loading these required secrets in via [python-dotenv](https://pypi.org/project/python-dotenv/), storing those secrets in a `.env` file.  This is always good practice for storing / loading secrets (e.g., doing so will reduce the chance you inadvertantly push secrets to a repo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "# reset pipelines for demo\n",
    "def reset_pipeline(pipeline):\n",
    "    current_files = pipeline.list(symbolic_directory_paths=[\"/*\"])\n",
    "    assert current_files[\"status_code\"] != 500\n",
    "    for item in current_files[\"items\"]:\n",
    "        delete_result = pipeline.delete(file_id=item[\"file_id\"])\n",
    "        assert delete_result[\"status_code\"] != 500\n",
    "    current_files = pipeline.list(symbolic_directory_paths=[\"/*\"])\n",
    "    assert current_files[\"status_code\"] != 500\n",
    "    assert len(current_files[\"items\"]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small function prints dictionaries very nicely in notebooks / markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dictionaries / json nicely in notebooks / markdown\n",
    "import json\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A table of contents for the remainder of this document is shown below.\n",
    "\n",
    "- [base pipeline setup](#base-pipeline-setup)\n",
    "- [the `.process` method](#the-.process-method)\n",
    "    - [core inputs to the `.process` method](#core-inputs-to-the-process-method)\n",
    "    - [basic usage and output breakdown](#basic-usage-and-output-breakdown)\n",
    "    - [optional input arguments](#optional-input-arguments)\n",
    "    - [defaults when using `.process`](#defaults-when-using-process)\n",
    "    - [automatic data type transformations](#automatic-data-type-transformations)\n",
    "- [the `.process_status` method](#the-process_status-method)\n",
    "- [the `.fetch_output` method](#the-fetch_output-method)\n",
    "- [the `.list` method](#the-list-method)\n",
    "    - [listing by `file_ids`](#listing-by-file_ids)\n",
    "    - [listing by `file_names`](#listing-by-file_names)\n",
    "    - [listing by `symbolic_directory_paths`](#listing-by-symbolic_directory_paths)\n",
    "    - [listing by `file_tags`](#listing-by-file_tags)\n",
    "    - [listing by `created_at` and `updated_at` bookend times](#listing-by-created_at-and-updated_at-bookend-times)\n",
    "    - [wildcard arguments](#wildcard-arguments)\n",
    "    - [using multiple arguments with `.list`](#using-multiple-arguments-with-list)\n",
    "- [the `.update` method](#the-update-method)\n",
    "- [the `.delete` method](#the-delete-method)\n",
    "- [the `.show_tree` method](#the-show_tree-method)\n",
    "- [the `.keyword_search` method](#the-keyword_search-method)\n",
    "    [a simple keyword search pipeline](#a-simple-keyword-search-pipeline)\n",
    "    [invoking the `keyword_search`  method](#invoking-the-keyword-search-method)\n",
    "- [the `.vector_search` method](#the-vector_search-method)\n",
    "    [a simple vector search pipeline](#a-simple-vector-search-pipeline)\n",
    "    [invoking the `vector_search`  method](#invoking-the-vector-search-method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base pipeline setup\n",
    "\n",
    "Below we setup a simple one module pipeline using the `parser` module, using the default `sentence` parser.  This parser takes in an input text file and splits into its constituent sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom module creation tools\n",
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# instantiate module\n",
    "module_1 = Module(module_type=\"parser\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='parser-pipeline-1', \n",
    "                        module_chain=[module_1])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this `pipeline` object for illustrative purposes for the remainder of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `.process` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.process` api is available to every krixik pipeline.  This api is invoked whenever you want to process files through your defined pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### core inputs to the `.process` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The api has five basic inputs, as well as a range of optional metdata.  These inputs are\n",
    "\n",
    "- `local_file_path`:  (required) the path to the local file you wish to process\n",
    "- `local_save_directory`: (optional) local location for saving process output (defaults to current working directory)\n",
    " - `expire_time`: (optional) length of time process output remains on krixik servers (default is 30 minutes / 1800 seconds)\n",
    "- `wait_for_process`: (optional) whether or not to wait for your process to complete before regaining control of your IDE or notebook - `True` means wait until the process is complete, `False` means regain control immediately after your file has uploaded for processing (default `True`)  When set to `False` the status of processing can be retrieved via the `.process_status` api [LINK HERE]\n",
    "- `verbose`: (optional) whether to show process update printouts at your terminal / notebook (default `True`)\n",
    "\n",
    "Lets process a simple file using these core inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic usage and output breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a path to a local input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at this file before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a bright cold day in April, and the clocks were striking thirteen.\n",
      "Winston Smith, his chin nuzzled into his breast in an effort to escape the\n",
      "vile wind, slipped quickly through the glass doors of Victory Mansions,\n",
      "though not quickly enough to prevent a swirl of gritty dust from entering\n",
      "along with him.\n"
     ]
    }
   ],
   "source": [
    "# examine contents of input file\n",
    "with open(test_file, \"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A paragraph of text consisting of two sentences.\n",
    "\n",
    "Now let's process it using our sentence parser and explore `.process` inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False)            # set verbosity to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below.  Because the output of this particular module-model pair is json, the process output is provided in the return response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"request_id\": \"e957e17f-ca3c-40bf-afd1-ebca1f27ba51\",\n",
      "  \"file_id\": \"9d94d011-b445-41fa-ae9e-92322726be96\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 9d94d011-b445-41fa-ae9e-92322726be96.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "      \"line_numbers\": [\n",
      "        1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "      \"line_numbers\": [\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"./9d94d011-b445-41fa-ae9e-92322726be96.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "json_print(process_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets break down the output:\n",
    "\n",
    "- `status_code`: provides the success / failure signal for the api\n",
    "- `pipeline`: the name of the pipeline we ran `.process` on\n",
    "- `request_id`: unique id associated with this execution of `.process`\n",
    "- `file_id`: unique id for the processed file and its associated output\n",
    "- `message`: message detailing success or failure of call\n",
    "- `warnings`: message list indicating any warnings related to our call\n",
    "- `process_output`: returned output (available when module-model output is json only)\n",
    "- `process_output_files`: list of process output, local file names \n",
    "\n",
    "We can see from `process_output` that our two-sentence paragraph input has been separated correctly.  Each sentence also has its corresponding line number(s).\n",
    "\n",
    "This process output is also stored in the file contained in `process_output_files`.  Lets load it in and confirm we have the same process output we see above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "    \"line_numbers\": [\n",
      "      1\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "    \"line_numbers\": [\n",
      "      2,\n",
      "      3,\n",
      "      4,\n",
      "      5\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# load in process output from file\n",
    "import json\n",
    "with open(process_output['process_output_files'][0], \"r\") as file:\n",
    "    process_output = json.load(file)\n",
    "    json_print(process_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optional input arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When using the api you may optionally include a variety of process metadata.  \n",
    " \n",
    "These optional do not change how `.process` runs or treats input / output data - they make your process output easier to retrieve and organize.   \n",
    "\n",
    "Optional inputs include\n",
    "\n",
    "- `symbolic_directory_path` - a unix formatted directory path (default is `/etc`)\n",
    "- `file_name` - a custom file name (randomly assigned name by default)\n",
    "- `file_tags` - a list of custom file tags (none by default)\n",
    "- `file_description` - a custom file description (none by default)\n",
    "\n",
    "The first three of these  - `symbolic_directory_path`, `file_name`, and `file_tags` - can be used to retrieve the record of your process at a later time using the `.list` api [LINK HERE].  They can also be used as filters for search if your pipeline ends with a `keyword-search` [LINK HERE] or `vector-search` [LINK HERE] module.\n",
    "\n",
    "The `file_description` can be used to provide a description of the file.\n",
    "\n",
    "Lets use the `.process` method with and without these arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False,            # set verbosity to False\n",
    "                                  symbolic_directory_path = \"/my/custom/filepath\",\n",
    "                                  file_name = \"some_snippets.txt\",\n",
    "                                  file_tags = [{\"author\": \"orwell\"}, {\"category\": \"fiction\"}],\n",
    "                                  file_description = \"the first paragraph of 1984\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defaults when using `.process`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if no `file_name` is provided a random name is provided for the process input file of the form `krixik_generated_file_name_{10 random chars}.ext`\n",
    "where here `ext` is the extension of your input provided by `local_file_path`\n",
    "\n",
    "- if no value for `symbolic_directory_path` is provided it is set to the default value of `/etc`\n",
    "\n",
    "- you cannot define `symbolic_directory_path`s that are children of `/etc` - e.g., `/etc/mypath` is not allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### automatic data type transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.process` method automatically transforms the following input data types from `local_file_path`\n",
    "\n",
    "- `pdf` -> `txt`\n",
    "- `docx` -> `txt`\n",
    "- `pptx` -> `txt`\n",
    "- `mp4` -> `mp3`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `.process_status` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.process_status` method lets you check the status of a pipeline usage of `.process` via a `request_id`.  This is epically useful when using `.process` with `wait_for_process` set to `False` [LINK HERE].\n",
    "\n",
    "To illustrate its usage, let us first process a file with our pipeline using `wait_for_process` set to `False`.  This will give us back control of our IDE / notebook as soon as the file has completed upload. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\",  # save output in current directory\n",
    "                                  expire_time=60*5,          # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=False,    # do not wait for process to complete before regaining ide\n",
    "                                  verbose=False)             # set verbosity to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us quickly examine the returned output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"file_id\": \"ce251869-5026-4026-ad40-35e2af5e73eb\",\n",
      "  \"request_id\": \"bcda2f5b-aaf9-5242-98d6-32e5fedbf5ff\",\n",
      "  \"file_name\": \"krixik_generated_file_name_hzufejnxft.txt\",\n",
      "  \"symbolic_directory_path\": \"/etc\",\n",
      "  \"file_tags\": null,\n",
      "  \"file_description\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "json_print(process_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the status of our process using returned `request_id` and the `.process_status` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"398f4ad1-bb93-4b4b-bfa4-8a26e618a068\",\n",
      "  \"file_id\": \"ce251869-5026-4026-ad40-35e2af5e73eb\",\n",
      "  \"message\": \"SUCCESS: process_status found\",\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"process_status\": {\n",
      "    \"parser\": true\n",
      "  },\n",
      "  \"overall_status\": \"complete\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# use .process_status\n",
    "status_output = pipeline.process_status(request_id=process_output[\"request_id\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(status_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the status of our single module has not yet completed.\n",
    "\n",
    "If we wait a few moments and try again, we will see confirmation that the process completed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"4f91cc57-9df7-4faa-bbfd-57fc3abd9a50\",\n",
      "  \"file_id\": \"ce251869-5026-4026-ad40-35e2af5e73eb\",\n",
      "  \"message\": \"SUCCESS: process_status found\",\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"process_status\": {\n",
      "    \"parser\": true\n",
      "  },\n",
      "  \"overall_status\": \"complete\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# use .process_status\n",
    "status_output = pipeline.process_status(request_id=process_output[\"request_id\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(status_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `.fetch_output` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.fetch_output` method is used to download the output of a pipeline process.  This is particularly useful when using `.process` with `wait_for_process` set to `False`, as your output is not immediately pulled.\n",
    "\n",
    "Lets see how this works by processing a file with `wait_for_process` set to `False`.  We will first use `.process_status` [LINK HERE] to make sure the file has completed processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  expire_time=60*5,          # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=False,    # do not wait for process to complete before regaining ide\n",
    "                                  verbose=False)             # set verbosity to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the status of our process via the returned `request_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"9f81bcbc-f523-48a8-a33a-5669547401af\",\n",
      "  \"file_id\": \"1488dd6d-4bc5-4d61-b7d5-ff5262fce5f1\",\n",
      "  \"message\": \"SUCCESS: process_status found\",\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"process_status\": {\n",
      "    \"parser\": false\n",
      "  },\n",
      "  \"overall_status\": \"ongoing\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# use .process_status\n",
    "status_output = pipeline.process_status(request_id=process_output[\"request_id\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(status_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the file has completed processing we can now use `.fetch_output`.\n",
    "\n",
    "`.fetch_output` takes in a two inputs\n",
    "\n",
    " - the `file_id` of the uploaded and processed file\n",
    " - a `local_save_directory` (optional) where the completed files will be saved locally (default is current working directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the output of our process using file_id\n",
    "fetch_output = pipeline.fetch_output(file_id=process_output[\"file_id\"],\n",
    "                                     local_save_directory=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the fetched output return we have our json returned in the `fetch_output` key-value.  \n",
    "\n",
    "The `process_output_files` key-value pair shows the download location(s) of our completed process files pulled by `.fetch_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"request_id\": \"66cacfdf-f4a8-4061-9322-50489d5d9670\",\n",
      "  \"file_id\": \"1488dd6d-4bc5-4d61-b7d5-ff5262fce5f1\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 1488dd6d-4bc5-4d61-b7d5-ff5262fce5f1.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "      \"line_numbers\": [\n",
      "        1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "      \"line_numbers\": [\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"./1488dd6d-4bc5-4d61-b7d5-ff5262fce5f1.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "json_print(fetch_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `.list` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using `.process` [LINK HERE] to process a file with your chosen pipeline, you can retrieve the associated record if this file using `list` method using its `file_id` and any other optional metadata you included.\n",
    "\n",
    "You can list multiple records with a single execution of `.list`, hence the inputs into `.list` are as follows:\n",
    "\n",
    "- `file_ids`: (optional) a list of `file_id`'s to return records for\n",
    "- `file_names`: (optional) a list of `file_id`'s to return records for\n",
    "- `symbolic_directory_paths`: (optional) a list of `symbolic_directory_paths`'s to return records for\n",
    "- `symbolic_file_paths`: (optional) a list of `symbolic_directory_path/file_name`'s to return records for\n",
    "- `file_tags`: (optional) a list of `file_tags`'s to return records for\n",
    "\n",
    "You may use wildcard operators with `file_names`, `symbolic_directory_paths`,`symbolic_file_paths`, and `file_tags` to retrieve records with fuzzy matching.\n",
    "\n",
    "You may also list by bookends on the creation and last updated times of your records.  These include:\n",
    "\n",
    "- `created_at_start`: the earliest `created_at` time for record you wish to retrieve\n",
    "- `created_at_end`: the latest `created_at` time for record you wish to retrieve\n",
    "- `last_updated_start`: the earliest `last_updated` time for record you wish to retrieve\n",
    "- `last_updated_end`: the latest `last_updated` time for record you wish to retrieve\n",
    "\n",
    "Moreover you may *mix* these arguments to retrieve records for very specific tranches of your process data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let start by processing a file, including optinoal metadata so that we can retrieve it via several core inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False,            # set verbosity to False\n",
    "                                  symbolic_directory_path = \"/my/custom/filepath\",\n",
    "                                  file_name = \"some_snippets.txt\",\n",
    "                                  file_tags = [{\"author\": \"orwell\"}, {\"category\": \"fiction\"}],\n",
    "                                  file_description = \"the first paragraph of 1984\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listing by `file_ids`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we list the record of this process using its `file_id`.\n",
    "\n",
    "Notice we place this in a list, since in practice we can call `.list` on a list of `file_id`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"11dcf756-702c-421c-a85a-49dabc2cca7f\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(file_ids=[process_output[\"file_id\"]])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listing by `file_names`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list this file via its `file_name`.  Again we place it in a list, since in practice we may provide a list of `file_name`'s to `.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"764587e3-7212-429b-baeb-0ba824797fa6\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(file_names=[\"some_snippets.txt\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listing by `symbolic_directory_paths`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list this file via its `symbolic_directory_path`.  Again we place it in a list, since in practice we may provide a list of `symbolic_directory_path`'s to `.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"70c71a76-7ce9-43c7-86e7-838b7fa93d8e\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(symbolic_directory_paths=[\"/my/custom/filepath\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listing by `file_tags`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list this file via its `file_tags`.  Again we place it in a list, since in practice we may provide a list of `file_tags`'s to `.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"7915929d-47cc-4fb9-82f6-b737ad823458\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:05\",\n",
      "      \"process_id\": \"578cb0a2-0f19-4d83-4b05-3c543f5e2506\",\n",
      "      \"created_at\": \"2024-04-26 21:05:05\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"fb228e8e-eefd-4c52-b966-a49506d63f34\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:05\",\n",
      "      \"file_name\": \"some_snippets.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(file_tags=[{\"author\": \"orwell\"}])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listing by `created_at` and `updated_at` bookend times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how to list by timestamp bookends we first process a file and record the current time (in UTC timezone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"request_id\": \"d3bca30e-d260-4c62-8aa9-91307b21d8b1\",\n",
      "  \"file_id\": \"3b941b6f-bd05-4fbb-83fd-6fea80c25629\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 3b941b6f-bd05-4fbb-83fd-6fea80c25629.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "      \"line_numbers\": [\n",
      "        1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "      \"line_numbers\": [\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"./3b941b6f-bd05-4fbb-83fd-6fea80c25629.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False)            # set verbosity to False\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(process_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now list by the `created_at` and `last_updated` timestamps - using bookends `_start` and/or `_end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"aacbb5e9-4701-454b-be2d-16d0f812a201\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:05:21\",\n",
      "      \"process_id\": \"132561f2-336b-c889-ba9e-500df80fdd38\",\n",
      "      \"created_at\": \"2024-04-26 21:05:21\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        },\n",
      "        \"pipeline_ordered_modules\": [\n",
      "          \"parser\"\n",
      "        ],\n",
      "        \"pipeline_output_process_keys\": [\n",
      "          \"snippet\"\n",
      "        ]\n",
      "      },\n",
      "      \"file_tags\": [],\n",
      "      \"file_description\": \"\",\n",
      "      \"symbolic_directory_path\": \"/etc\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"3b941b6f-bd05-4fbb-83fd-6fea80c25629\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:21\",\n",
      "      \"file_name\": \"krixik_generated_file_name_zqdsvltyrw.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(created_at_start=list_output[\"items\"][0][\"created_at\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wildcard arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use wildcard * to use fuzzy matching with your record selection as well.\n",
    "\n",
    "For `file_names` and `symbolic_directory_paths` a wildcard may be used as both prefix and suffix.\n",
    "\n",
    "For `file_tags` a wildcard may be used for the value of a tag dictioary to search across all records with a corresopnding key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"341c4e07-62a6-47f0-904b-7ff2ee3bbaef\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"file_names\": [\n",
      "            \"some*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using wildcard(s)\n",
    "list_output = pipeline.list(file_names=[\"some*\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"b6d53064-2748-4c3a-ac7a-e0325cf8c58f\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"symbolic_directory_paths\": [\n",
      "            \"/my/*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using wildcard(s)\n",
    "list_output = pipeline.list(symbolic_directory_paths=[\"/my/*\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"de17823f-5601-4143-b2ae-c546c173cdc7\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"file_tags_keys\": [\n",
      "            \"author\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using wildcard(s)\n",
    "list_output = pipeline.list(file_tags=[{\"author\": \"*\"}])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using multiple arguments with `.list`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use multiple input arguments jointly with `.list`.  Multiple inputs are combined in a logical AND to retrieve records satisfying all input requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"091a2b5e-4d2f-44cd-9fcf-65a0c80546b7\",\n",
      "  \"message\": \"No files were found for the given query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following arguments returned zero results\": [\n",
      "        {\n",
      "          \"symbolic_directory_paths\": [\n",
      "            \"/my/*\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"file_names\": [\n",
      "            \"some*\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records using a mix of input args\n",
    "list_output = pipeline.list(file_names = [\"some*\"],\n",
    "                            symbolic_directory_paths=[\"/my/*\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `.update` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can update the metadata of a file using the `update` method.  This method takes in the `file_id` of the file you would like to update, and the metadata you would like to update.  \n",
    "\n",
    "You can update any of the following metadata: `expire_time`,  `symbolic_directory_path`, `file_name`, `file_tags`, or `file_description` of the associated file using this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate the use of `.update` by first processing a simple file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False,            # set verbosity to False\n",
    "                                  symbolic_directory_path = \"/my/custom/filepath\",\n",
    "                                  file_name = \"some_snippets_3.txt\",\n",
    "                                  file_tags = [{\"author\": \"orwell\"}, {\"category\": \"fiction\"}],\n",
    "                                  file_description = \"the first paragraph of 1984\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use `.update` to change its `file_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"request_id\": \"4201b289-9088-42e3-a0ec-8053b9190ba3\",\n",
      "  \"message\": \"Successfully updated file metadata\",\n",
      "  \"warnings\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# update a process record metadata\n",
    "update_output = pipeline.update(file_id=process_output[\"file_id\"],\n",
    "                                file_name=\"a_new_filename.txt\")\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(update_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we use `.list` [LINK HERE] we can check that our record metadata has been changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"53c2fc7b-8b84-4128-a34e-1e4de4ceff94\",\n",
      "  \"message\": \"Successfully returned 1 item.  Note: all timestamps in UTC.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"last_updated\": \"2024-04-26 21:06:32\",\n",
      "      \"process_id\": \"461bfe88-0064-13b1-2728-7f5a371092cf\",\n",
      "      \"created_at\": \"2024-04-26 21:05:42\",\n",
      "      \"file_metadata\": {\n",
      "        \"modules\": {\n",
      "          \"parser\": {\n",
      "            \"model\": \"sentence\"\n",
      "          }\n",
      "        },\n",
      "        \"modules_data\": {\n",
      "          \"parser\": {\n",
      "            \"data_files_extensions\": [\n",
      "              \".json\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"file_tags\": [\n",
      "        {\n",
      "          \"author\": \"orwell\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"fiction\"\n",
      "        }\n",
      "      ],\n",
      "      \"file_description\": \"the first paragraph of 1984\",\n",
      "      \"symbolic_directory_path\": \"/my/custom/filepath\",\n",
      "      \"pipeline\": \"parser-pipeline-1\",\n",
      "      \"file_id\": \"ca3ca26c-7b76-4fd2-a1f1-3c86d8eb443a\",\n",
      "      \"expire_time\": \"2024-04-26 21:10:42\",\n",
      "      \"file_name\": \"a_new_filename.txt\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(file_ids=[process_output[\"file_id\"]])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `.delete` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can delete the record of your process on demand using the `delete` method.  This will remove all record of the process from our servers.  This is the manual version of letting the `expire_time` run out on a file.\n",
    "\n",
    "The `.delete` method takes in a single argument: the `file_id` of the file you wish to delete.\n",
    "\n",
    "We will illustrate its usage by processing a simple file, deleting it using the `.delete` method, and then checking that it no longer exists using the `.list` method [LINK HERE]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False)            # set verbosity to False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we delete this process record and its output via its `file_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"parser-pipeline-1\",\n",
      "  \"request_id\": \"693d3da8-1e0d-4f24-b85a-2c8287320b51\",\n",
      "  \"message\": \"Successfully deleted file_id: ddb925f3-8cfb-4fdc-bd10-dbb68adecb04\",\n",
      "  \"warnings\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# delete process record and output by file_id\n",
    "delete_output = pipeline.delete(file_id=process_output[\"file_id\"])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(delete_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check that the file has been deleted using `.list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"b4f69db4-fece-4b3d-8184-420ebfd912d2\",\n",
      "  \"message\": \"No items found for input query arguments\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following file_ids were not found\": [\n",
      "        \"ddb925f3-8cfb-4fdc-bd10-dbb68adecb04\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# list process records\n",
    "list_output = pipeline.list(file_ids=[process_output[\"file_id\"]])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(list_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `.show_tree` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_tree` is a convenience function for visualizing - at your terminal or IDE output - your un-expired pipeline files.  It is designed as a simple analog to the standard unix [tree command](https://www.tecmint.com/linux-tree-command-examples/).\n",
    "\n",
    "To illustrate its usage we first process several files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False,\n",
    "                                  symbolic_directory_path=\"/my/custom/path\",\n",
    "                                  file_name=\"file_num_one.txt\")   \n",
    "\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False,\n",
    "                                  symbolic_directory_path=\"/my/custom/path\",\n",
    "                                  file_name=\"file_num_two.txt\")   \n",
    "\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False,\n",
    "                                  symbolic_directory_path=\"/my/custom/path/subpath\",\n",
    "                                  file_name=\"file_num_three.txt\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize our pipeline process file directory structure using `show_tree`.\n",
    "\n",
    "`show_tree` takes in a single argument - `symbolic_directory_path`.  You can enter a path or stump (path + wildcard) to see all files and directories at or below the input path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "└── /my\n",
      "    └── /custom\n",
      "        └── /path\n",
      "            ├── file_num_one.txt\n",
      "            ├── file_num_two.txt\n",
      "            └── /subpath\n",
      "                └── file_num_three.txt\n"
     ]
    }
   ],
   "source": [
    "# show the directory structure of a pipeline process file directory\n",
    "show_tree_output = pipeline.show_tree(symbolic_directory_path='/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `.keyword_search` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.keyword_search` method can be used with any pipeline that ends with `keyword-search` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a simple keyword search pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we construct the simplest custom pipeline that satisfies this criteria - a pipeline consisting of the `keyword-search` module alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom module creation tools\n",
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# instantiate module\n",
    "module_1 = Module(module_type=\"keyword-search\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='keyword-search-pipeline-1', \n",
    "                        module_chain=[module_1])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invoking the `keyword_search`  method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform any of the core system methods on our custom pipeline (e.g., `.process`, `.list`, etc.,).  Additionally we can invoke the `keyword_search` method.\n",
    "\n",
    "Lets first process a file with our new pipeline.  The `keyword-search` module takes in a text file, and returns `sqlite` keyword database consisting of all non-trivial `(keyword, line_number, token_number)` tuples from the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"keyword-search-pipeline-1\",\n",
      "  \"request_id\": \"d1a2cfe0-2d28-41ff-93bb-c262cc2bcab4\",\n",
      "  \"file_id\": \"83279d22-2f50-48fd-8650-f8a58e7ce103\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 83279d22-2f50-48fd-8650-f8a58e7ce103.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"./83279d22-2f50-48fd-8650-f8a58e7ce103.db\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False)            # set verbosity to False\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(process_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we did not define a `file_name` or `symbolic_directory_path` ourselves, so defaults will be given as described in the `.process` walkthrough [LINK HERE]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the `process_output` key value is `null` since the return object is a database.  We can see this database in the local location provided in the `process_output_files` value.\n",
    "\n",
    "With `.process` complete we can run `keyword_search` on our input file. \n",
    "\n",
    "The `keyword_search` method takes in the exact same arguments as `.list` [LINK HERE] - that is `file_ids`, `file_names`, etc., - plus one additional argument: `query`.  The `query` is a string of words to be queried individually.\n",
    "\n",
    "Let's look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"98034dfa-eb3c-4950-b8b6-e205f5355531\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [\n",
      "    {\n",
      "      \"WARNING: the following words in the query are in the stop_words list and thus no results will be returned for them\": [\n",
      "        \"it\",\n",
      "        \"was\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"83279d22-2f50-48fd-8650-f8a58e7ce103\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_file_name_pcirbljkok.txt\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_lines\": 5,\n",
      "        \"created_at\": \"2024-04-26 21:10:22\",\n",
      "        \"last_updated\": \"2024-04-26 21:10:22\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"keyword\": \"cold\",\n",
      "          \"line_number\": 1,\n",
      "          \"keyword_number\": 5\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# perform keyword_search over the input file\n",
    "keyword_output = pipeline.keyword_search(query=\"it was cold night\",\n",
    "                                         file_ids=[process_output[\"file_id\"]])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(keyword_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one returned search result in `items`, as well as stop words removed from the input query shown in the return `warnings`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `.vector_search` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "krixik's `vector_search` method is a convenience function for both embedding and querying - and so can only be used with pipelines containing both `text-embedder` and `vector-search` modules in succession.\n",
    "\n",
    "Below we construct the simplest custom pipeline that satisfies this criteria - a standard vector search pipeline consisting of three modules: a `parser`, `text-embedder`, and `vector-search` index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a simple vector search pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we construct the simplest custom pipeline that satisfies this criteria - a standard vector search pipeline consisting of three modules: a `parser`, `text-embedder`, and `vector-search` index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom module creation tools\n",
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# instantiate module\n",
    "module_1 = Module(module_type=\"parser\")\n",
    "module_2 = Module(module_type=\"text-embedder\")\n",
    "module_3 = Module(module_type=\"vector-search\")\n",
    "\n",
    "# create custom pipeline object\n",
    "custom = CreatePipeline(name='vector-search-pipeline-1', \n",
    "                        module_chain=[module_1, module_2, module_3])\n",
    "\n",
    "# pass the custom object to the krixik operator (note you can also do this by passing its config)\n",
    "pipeline = krixik.load_pipeline(pipeline=custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invoking the `vector_search`  method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform any of the core system methods on our custom pipeline (e.g., `.process`, `.list`, etc.,).  Additionally we can invoke the `vector_search` method.\n",
    "\n",
    "Lets first process a file with our new pipeline.  The `vector-search` module takes in a text file, and returns `faiss` vector database consisting of all non-trivial `(snippet, line_numbers)` tuples from the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"vector-search-pipeline-1\",\n",
      "  \"request_id\": \"1a09068c-872a-4389-a399-7281e2d1764e\",\n",
      "  \"file_id\": \"f69aac3d-e674-45d5-ab33-f16196ce82b2\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id f69aac3d-e674-45d5-ab33-f16196ce82b2.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": null,\n",
      "  \"process_output_files\": [\n",
      "    \"./f69aac3d-e674-45d5-ab33-f16196ce82b2.faiss\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False)            # set verbosity to False\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(process_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we did not define a `file_name` or `symbolic_directory_path` ourselves, so defaults will be given as described in the `.process` walkthrough [LINK HERE]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the `process_output` key value is `null` since the return object is a database.  We can see this database in the local location provided in the `process_output_files` value.\n",
    "\n",
    "With `.process` complete we can run `vector_search` on our input file. \n",
    "\n",
    "The `vector_search` method takes in the exact same arguments as `.list` [LINK HERE] - that is `file_ids`, `file_names`, etc., - plus one additional argument: `query`.  The `query` is a string of words to be queried individually.\n",
    "\n",
    "Let's look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"request_id\": \"10503c1c-3959-4897-9315-a69438ecce2b\",\n",
      "  \"message\": \"Successfully queried 1 user file.\",\n",
      "  \"warnings\": [],\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"file_id\": \"f69aac3d-e674-45d5-ab33-f16196ce82b2\",\n",
      "      \"file_metadata\": {\n",
      "        \"file_name\": \"krixik_generated_file_name_awiouirlff.txt\",\n",
      "        \"symbolic_directory_path\": \"/etc\",\n",
      "        \"file_tags\": [],\n",
      "        \"num_vectors\": 2,\n",
      "        \"created_at\": \"2024-04-26 21:10:50\",\n",
      "        \"last_updated\": \"2024-04-26 21:10:50\"\n",
      "      },\n",
      "      \"search_results\": [\n",
      "        {\n",
      "          \"snippet\": \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
      "          \"line_numbers\": [\n",
      "            1\n",
      "          ],\n",
      "          \"distance\": 0.224\n",
      "        },\n",
      "        {\n",
      "          \"snippet\": \"Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.\",\n",
      "          \"line_numbers\": [\n",
      "            2,\n",
      "            3,\n",
      "            4,\n",
      "            5\n",
      "          ],\n",
      "          \"distance\": 0.417\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# perform vector_search over the input file\n",
    "vector_output = pipeline.vector_search(query=\"it was cold night\",\n",
    "                                        file_ids=[process_output[\"file_id\"]])\n",
    "\n",
    "# nicely print the output of this process\n",
    "json_print(vector_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one returned search result in `items`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
