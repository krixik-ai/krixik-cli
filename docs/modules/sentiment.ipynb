{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `sentiment` module\n",
    "\n",
    "This document reviews the `sentiment` module - which takes as input a json of string snippets and returns the snippets in a json along with their sentiment scores.\n",
    "\n",
    "This document includes an overview of custom pipeline setup, current model set, parameters, and `.process` usage for this module.\n",
    "\n",
    "To follow along with this demonstration be sure to initialize your krixik session with your api key and url as shown below. \n",
    "\n",
    "We illustrate loading these required secrets in via [python-dotenv](https://pypi.org/project/python-dotenv/), storing those secrets in a `.env` file.  This is always good practice for storing / loading secrets (e.g., doing so will reduce the chance you inadvertantly push secrets to a repo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../')\n",
    "from docs.utilities.reset import reset_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: You are now authenticated.\n"
     ]
    }
   ],
   "source": [
    "# load secrets from a .env file using python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"../.env\")\n",
    "MY_API_KEY = os.getenv('MY_API_KEY')\n",
    "MY_API_URL = os.getenv('MY_API_URL')\n",
    "\n",
    "# import krixik and initialize it with your personal secrets\n",
    "from krixik import krixik\n",
    "krixik.init(api_key = MY_API_KEY, \n",
    "            api_url = MY_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small function prints dictionaries very nicely in notebooks / markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dictionaries / json nicely in notebooks / markdown\n",
    "import json\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A table of contents for the remainder of this document is shown below.\n",
    "\n",
    "\n",
    "- [pipeline setup](#pipeline-setup)\n",
    "- [required input format](#required-input-format)\n",
    "- [using the default model](#using-the-default-model)\n",
    "- [using a non-default model](#using-a-non-default-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline setup\n",
    "\n",
    "Below we setup a simple one module pipeline using the `sentiment` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline with a single module\n",
    "pipeline = krixik.create_pipeline(name=\"my-sentiment-pipeline\",\n",
    "                                  module_chain=[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sentiment` module comes with a single model:\n",
    "\n",
    "- `distilbert-base-uncased-finetuned-sst-2-english`: (default)\n",
    "\n",
    "These available modeling options and parameters are stored in our custom pipeline's configuration (described further in LINK HERE).  We can examine this configuration as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipeline\": {\n",
      "    \"name\": \"my-sentiment-pipeline\",\n",
      "    \"modules\": [\n",
      "      {\n",
      "        \"name\": \"sentiment\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"bert-base-multilingual-uncased-sentiment\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"distilbert-base-multilingual-cased-sentiments-student\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"distilroberta-finetuned-financial-news-sentiment-analysis\"\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"json\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".json\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"json\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print pipeline configuration\n",
    "json_print(pipeline.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the models and their associated parameters available for use.\n",
    "\n",
    "You can save this configuration to disk as well by executing\n",
    "\n",
    "\n",
    "```python\n",
    "pipeline.save(\"/valid/path/file.yml\")\n",
    "```\n",
    "\n",
    "You can instantiate a pipeline directly from its configuration using the [.load_pipeline method](LINK HERE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "# delete all processed datapoints belonging to this pipeline\n",
    "reset_pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required input format\n",
    "\n",
    "This module accepts as input `.json` files consisting of a *list of dictionaries*.  Each dictionary may have as many key-value pairs as desired, but *must* contain the key name *snippet*.  This is the key `json-to-txt` will act on.\n",
    "\n",
    "Let's look at an example of a small valid input - and then process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"snippet\": \"I love this movie and i would watch it again and again!\"\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"Operating profit totaled EUR 9.4 mn, down from EUR 11.7 mn in 2004.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# examine contents of a valid input file\n",
    "test_file = \"../input_data/valid.json\"\n",
    "with open(test_file) as f:\n",
    "    json_print(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the default model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the small input file above using the default model - `base`.  Because `base` is the default model we need not input the optional `modules` argument into `.process`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../input_data/valid.json\"\n",
    "\n",
    "# process for search\n",
    "process_output = pipeline.process(local_file_path = test_file,\n",
    "                                  local_save_directory=\".\", # save output in current directory\n",
    "                                  expire_time=60*5,         # set all process data to expire in 5 minutes\n",
    "                                  wait_for_process=True,    # wait for process to complete before regaining ide\n",
    "                                  verbose=False)            # set verbosity to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is printed below.  Because the output of this particular module-model pair is text, the process output is provided in this object is null.  However the file itself has been returned to the address noted in the `process_output_files` key.  The `file_id` of the processed input is used as a filename prefix for the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status_code\": 200,\n",
      "  \"pipeline\": \"my-sentiment-pipeline\",\n",
      "  \"request_id\": \"b8f3860c-05a2-4a0e-aab2-c3bb4af94f9f\",\n",
      "  \"file_id\": \"5bd5b6e4-86b1-413e-9863-ed96ef34295b\",\n",
      "  \"message\": \"SUCCESS - output fetched for file_id 5bd5b6e4-86b1-413e-9863-ed96ef34295b.Output saved to location(s) listed in process_output_files.\",\n",
      "  \"warnings\": [],\n",
      "  \"process_output\": [\n",
      "    {\n",
      "      \"snippet\": \"I love this movie and i would watch it again and again!\",\n",
      "      \"positive\": 1.0,\n",
      "      \"negative\": 0.0,\n",
      "      \"neutral\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"snippet\": \"Operating profit totaled EUR 9.4 mn, down from EUR 11.7 mn in 2004.\",\n",
      "      \"positive\": 0.021,\n",
      "      \"negative\": 0.979,\n",
      "      \"neutral\": 0.0\n",
      "    }\n",
      "  ],\n",
      "  \"process_output_files\": [\n",
      "    \"./5bd5b6e4-86b1-413e-9863-ed96ef34295b.json\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# nicely print the output of this process\n",
    "json_print(process_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load in the text file output from `process_output_files` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"snippet\": \"I love this movie and i would watch it again and again!\",\n",
      "    \"positive\": 1.0,\n",
      "    \"negative\": 0.0,\n",
      "    \"neutral\": 0.0\n",
      "  },\n",
      "  {\n",
      "    \"snippet\": \"Operating profit totaled EUR 9.4 mn, down from EUR 11.7 mn in 2004.\",\n",
      "    \"positive\": 0.021,\n",
      "    \"negative\": 0.979,\n",
      "    \"neutral\": 0.0\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# load in process output from file\n",
    "import json\n",
    "with open(process_output['process_output_files'][0], \"r\") as file:\n",
    "    json_print(json.load(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see our two input sentences from the input have been concatenated successfully into a single text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
