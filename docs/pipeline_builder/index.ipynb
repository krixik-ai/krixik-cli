{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_convert"
    ]
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your first custom krixik pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With krixik *modules* are the building blocks of *pipelines*.  *Moduels* - consisting of both AI models and supporting functions.  \n",
    "\n",
    "We start off this Section by describing the necessary steps to get started building pipelines with modules.  Advanced details on modules may be found in Section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following small function to print dictionaries and json files more prettily to cell output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dictionaries / json nicely in notebooks / markdown\n",
    "import json\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing available modules\n",
    "\n",
    "To see all available modules use the following krixik api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caption',\n",
       " 'json-to-txt',\n",
       " 'keyword-search',\n",
       " 'ocr',\n",
       " 'parser',\n",
       " 'sentiment',\n",
       " 'summarize',\n",
       " 'text-embedder',\n",
       " 'transcribe',\n",
       " 'translate',\n",
       " 'vector-search']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from krixik import krixik\n",
    "\n",
    "# see all currently available modules\n",
    "krixik.available_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Creating modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a few instances of the available modules shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "\n",
    "# create a few modules\n",
    "module_1 = Module(module_type='transcribe')\n",
    "module_2 = Module(module_type='text-embedder')\n",
    "module_3 = Module(module_type=\"vector-search\")\n",
    "module_4 = Module(module_type=\"parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once instantiated we can examine the metadata of these instances or connect them into a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3  Viewing a module's `config` metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the highest level metadata on this module can be viewed via the `.config` property.\n",
    "\n",
    "This high level information is especially useful when *processing* data with a module in a pipeline, but its also a great place to get started in understanding current module offerings.  \n",
    "\n",
    "Specifically, `.config` tells you about a module's defaults, available models, and what kind of input/output data you need / should expect as output from the module.\n",
    "\n",
    "Lets take a look at our first module's `.config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"module\": {\n",
      "    \"name\": \"transcribe\",\n",
      "    \"models\": [\n",
      "      {\n",
      "        \"name\": \"whisper-tiny\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"whisper-base\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"whisper-small\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"whisper-medium\"\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"whisper-large-v3\"\n",
      "      }\n",
      "    ],\n",
      "    \"input\": {\n",
      "      \"type\": \"audio\",\n",
      "      \"permitted_extensions\": [\n",
      "        \".mp3\",\n",
      "        \".mp4\"\n",
      "      ]\n",
      "    },\n",
      "    \"output\": {\n",
      "      \"type\": \"json\",\n",
      "      \"permitted_extensions\": [\n",
      "        \".json\"\n",
      "      ]\n",
      "    },\n",
      "    \"defaults\": {\n",
      "      \"model\": \"whisper-tiny\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print a dictionary nicely in an ide or notebook\n",
    "json_print(module_1.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the second module's.  In this case we see that each module has a `quantize` parameter that can be set at processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"module\": {\n",
      "    \"name\": \"text-embedder\",\n",
      "    \"models\": [\n",
      "      {\n",
      "        \"name\": \"multi-qa-MiniLM-L6-cos-v1\",\n",
      "        \"params\": {\n",
      "          \"quantize\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"default\": true\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"msmarco-distilbert-dot-v5\",\n",
      "        \"params\": {\n",
      "          \"quantize\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"default\": true\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"all-MiniLM-L12-v2\",\n",
      "        \"params\": {\n",
      "          \"quantize\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"default\": true\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"all-mpnet-base-v2\",\n",
      "        \"params\": {\n",
      "          \"quantize\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"default\": true\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"all-MiniLM-L6-v2\",\n",
      "        \"params\": {\n",
      "          \"quantize\": {\n",
      "            \"type\": \"bool\",\n",
      "            \"default\": true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"input\": {\n",
      "      \"type\": \"json\",\n",
      "      \"permitted_extensions\": [\n",
      "        \".json\"\n",
      "      ]\n",
      "    },\n",
      "    \"output\": {\n",
      "      \"type\": \"npy\",\n",
      "      \"permitted_extensions\": [\n",
      "        \".npy\"\n",
      "      ]\n",
      "    },\n",
      "    \"defaults\": {\n",
      "      \"model\": \"multi-qa-MiniLM-L6-cos-v1\",\n",
      "      \"params\": {\n",
      "        \"quantize\": true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print a dictionary nicely in an ide or notebook\n",
    "json_print(module_2.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced module data properties are described in Sectino 2.  Their knowledge is not pre-requisite to building pipelines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4  Building your first pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a standard text search pipeline using modules.\n",
    " \n",
    "First we instantiate our modules - here we need the `parser`, `text-embedder`, and `vector-search` modules.  The `parser` currently takes care of setting up `keyword-search`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "\n",
    "# define a text search pipeline using modules\n",
    "parser = Module(module_type='parser')\n",
    "text_embedder = Module(module_type='text-embedder')\n",
    "vector_search = Module(module_type='vector-search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make a pipeline from these four modules that looks like this\n",
    "\n",
    "`parser` --> `text-embedder` --> `vector-search`\n",
    "\n",
    "That is, a sequence of discrete processing steps:\n",
    "\n",
    "- the `parser` module takes a *json* file as *input* and outputs a *json* file of text snippets\n",
    "- the `text-embedder` processes as *input* the *json* output from the `parser`'s and produces numpy *output*\n",
    "- the `vector-search` module takes as *input* the numpy *output* from `text-embedder` and produces a vector index as *output*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our modules instantiated they can be added one a time using pipeline's `.add` api, or all together at instantiation of the pipeline.  \n",
    "\n",
    "When taking the latter approach the modules are simply placed in order into a list called `module_chain` as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "text_search_pipeline = CreatePipeline(name='my-text-search-pipeline', \n",
    "                                      module_chain=[parser, text_embedder, vector_search])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection or \"click-ability\" tests are performed on the instantiation of this object.  These guarantee proper flow of input/output information through the defined module chain of the pipeline.\n",
    "\n",
    "These tests catch incompatible module connections.  For example if we try the pipeline\n",
    "\n",
    "`vector-search` --> `text-embedder`\n",
    "\n",
    "our instantiation will fail with a message about *why* the connection won't work. \n",
    "\n",
    " Lets try (and fail) to build this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "format type mismatch between vector-search - whose output format is faiss - and text-embedder - whose input format is json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkrixik\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_builder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CreatePipeline\n\u001b[0;32m----> 3\u001b[0m fail_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mCreatePipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmy-failed-pipeline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmodule_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mvector_search\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_embedder\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/docs/system/../../krixik/pipeline_builder/pipeline.py:58\u001b[0m, in \u001b[0;36mCreatePipeline.__init__\u001b[0;34m(self, name, module_chain, config_path)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipelines cannot currently have more than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_MODULES\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m modules\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m module_chain:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_connections()\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/docs/system/../../krixik/pipeline_builder/pipeline.py:83\u001b[0m, in \u001b[0;36mCreatePipeline.add\u001b[0;34m(self, module, insert_index)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__module_chain_configs\u001b[38;5;241m.\u001b[39mappend(module\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__module_chain_output_process_keys\u001b[38;5;241m.\u001b[39mappend(module\u001b[38;5;241m.\u001b[39moutput_process_key)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_connections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/docs/system/../../krixik/pipeline_builder/pipeline.py:160\u001b[0m, in \u001b[0;36mCreatePipeline.test_connections\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# check format compatibility\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prev_module_output_format \u001b[38;5;241m!=\u001b[39m curr_module_input_format:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat type mismatch between \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprev_module\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - whose output format is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprev_module_output_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_module\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - whose input format is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_module_input_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# check process key type compatibility\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    166\u001b[0m     prev_module_output_process_key_type\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;241m!=\u001b[39m curr_module_input_process_key_type\n\u001b[1;32m    168\u001b[0m ):\n",
      "\u001b[0;31mTypeError\u001b[0m: format type mismatch between vector-search - whose output format is faiss - and text-embedder - whose input format is json"
     ]
    }
   ],
   "source": [
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "fail_pipeline = CreatePipeline(name='my-failed-pipeline', \n",
    "                               module_chain=[vector_search, text_embedder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details on what's happening with these tests see Section 2 of this document.  For now the details are not critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5  Testing input in your pipeline\n",
    "\n",
    "You can test whether inputs to your pipeline will flow properly through it by using your pipeline's `.test_input` api. \n",
    "\n",
    "We illustrate this below with both a valid and invalid file for our `text_search_pipeline` above.\n",
    "\n",
    "Make sure to examine your modules' configs or your pipeline config (detailed in the next subsection) - and in particular the first module's config - to understand allowable input data types and file extensions for your pipeline.  \n",
    "\n",
    "This test does not execute your pipeline.  It makes sure your input file is consumable by the first module of your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: local file ../../examples/input_data/1984_very_short.txt passed pipeline input test passed\n"
     ]
    }
   ],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/1984_very_short.txt\"\n",
    "\n",
    "# use .test_input to ensure the pipeline is working as expected on test files\n",
    "text_search_pipeline.test_input(local_file_path=test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "file extension .png does not match the expected input format text",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/docs/system/../../krixik/utilities/validators/data/utilities/decorators.py:46\u001b[0m, in \u001b[0;36mdatatype_validator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid file extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/docs/system/../../krixik/pipeline_builder/pipeline.py:125\u001b[0m, in \u001b[0;36mCreatePipeline.test_input\u001b[0;34m(self, local_file_path)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ext_format \u001b[38;5;241m!=\u001b[39m first_module_input_format:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile extension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_ext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match the expected input format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_module_input_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m is_valid(first_module\u001b[38;5;241m.\u001b[39mname, local_file_path)\n",
      "\u001b[0;31mTypeError\u001b[0m: file extension .png does not match the expected input format text",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m test_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../examples/input_data/seal.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# use .test_input to ensure the pipeline is working as expected on test files\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtext_search_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/krixik/krixik_cli/docs/system/../../krixik/utilities/validators/data/utilities/decorators.py:50\u001b[0m, in \u001b[0;36mdatatype_validator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(e)\n",
      "\u001b[0;31mException\u001b[0m: file extension .png does not match the expected input format text"
     ]
    }
   ],
   "source": [
    "# define path to an input file from examples directory\n",
    "test_file = \"../../examples/input_data/seal.png\"\n",
    "\n",
    "# use .test_input to ensure the pipeline is working as expected on test files\n",
    "text_search_pipeline.test_input(local_file_path=test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the relevant data class of your starting module to ensure your input satisfies the required input structure requirements.\n",
    "\n",
    "You can get a quick sense of its required structure by looking at a sample datapoint as shown in the next few cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data example\n",
      "-----\n",
      "sample text looks like this.\n",
      "\n",
      "\n",
      "output data example\n",
      "-----\n",
      "{\n",
      "  \"snippet\": \"This is the main text.\",\n",
      "  \"line_numbers\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    4\n",
      "  ],\n",
      "  \"other\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# exampine the required input / output data structure for the parser module by printing an example of each\n",
    "from krixik.modules.parser import io\n",
    "import json\n",
    "print('input data example')\n",
    "print('-----')\n",
    "print(io.InputStructure().data_example)\n",
    "print('\\n')\n",
    "print('output data example')\n",
    "print('-----')\n",
    "print(json.dumps(io.OutputStructure().data_example, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `other` denotes any other key in your input.  Its value is arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a deeper understanding of module io you can examine its `dataclass` as detailed in Section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Useful pipeline data properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some valuable data properties and apis of our pipeline `text_search_pipeline`. \n",
    "\n",
    "To view the module chain of your pipeline, use the `.module_chain` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parser', 'text-embedder', 'vector-search']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the module chain of your pipeline using the .module_chain property\n",
    "text_search_pipeline.module_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more detailed view of your pipeline, including details on permissible input/output data types and extensions, use the `.config` property.  This essentially centralizes your pipeline's module configs in one place.\n",
    "\n",
    "Your pipeline config file is also how you save / load your pipeline (so you do not need to go through the pythonic steps of building it each time you want to use it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipeline\": {\n",
      "    \"name\": \"my-text-search-pipeline\",\n",
      "    \"modules\": [\n",
      "      {\n",
      "        \"name\": \"parser\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"sentence\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"fixed\",\n",
      "            \"params\": {\n",
      "              \"chunk_size\": {\n",
      "                \"type\": \"int\",\n",
      "                \"default\": 10\n",
      "              },\n",
      "              \"overlap_size\": {\n",
      "                \"type\": \"int\",\n",
      "                \"default\": 2\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"sentence\"\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"text\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".txt\",\n",
      "            \".pdf\",\n",
      "            \".docx\",\n",
      "            \".pptx\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"json\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"text-embedder\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"multi-qa-MiniLM-L6-cos-v1\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"msmarco-distilbert-dot-v5\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"all-MiniLM-L12-v2\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"all-mpnet-base-v2\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"all-MiniLM-L6-v2\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"multi-qa-MiniLM-L6-cos-v1\",\n",
      "          \"params\": {\n",
      "            \"quantize\": true\n",
      "          }\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"json\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".json\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"npy\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"vector-search\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"faiss\"\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"faiss\"\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"npy\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".npy\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"faiss\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# examine a pipeline's high level data by using the .config property\n",
    "# print a dictionary nicely in an ide or notebook\n",
    "json_print(text_search_pipeline.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7  Saving your pipeline config\n",
    "\n",
    "Once your pipeline is built, connection tested, and input tested, it's a good idea to save its config.  This allows you to load your pipeline directly from file in the future, saving the hassle of having to rebuild it pythonically each time you want to use it. \n",
    "\n",
    "To save the config file of a pipeline use the `.save` method, providing a path to a local `.yml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your pipeline config to a .yaml file\n",
    "text_search_pipeline.save('text_search_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8  Loading your pipeline from file\n",
    "\n",
    "Load your pipeline either directly on instantiation or by using the `.load` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# load pipeline directly on instantiation\n",
    "reloaded_pipeline = CreatePipeline(config_path = 'text_search_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipeline\": {\n",
      "    \"name\": \"my-text-search-pipeline\",\n",
      "    \"modules\": [\n",
      "      {\n",
      "        \"name\": \"parser\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"sentence\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"fixed\",\n",
      "            \"params\": {\n",
      "              \"chunk_size\": {\n",
      "                \"type\": \"int\",\n",
      "                \"default\": 10\n",
      "              },\n",
      "              \"overlap_size\": {\n",
      "                \"type\": \"int\",\n",
      "                \"default\": 2\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"sentence\"\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"text\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".txt\",\n",
      "            \".pdf\",\n",
      "            \".docx\",\n",
      "            \".pptx\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"json\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"text-embedder\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"multi-qa-MiniLM-L6-cos-v1\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"msmarco-distilbert-dot-v5\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"all-MiniLM-L12-v2\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"all-mpnet-base-v2\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"all-MiniLM-L6-v2\",\n",
      "            \"params\": {\n",
      "              \"quantize\": {\n",
      "                \"type\": \"bool\",\n",
      "                \"default\": true\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"multi-qa-MiniLM-L6-cos-v1\",\n",
      "          \"params\": {\n",
      "            \"quantize\": true\n",
      "          }\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"json\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".json\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"npy\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"vector-search\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"faiss\"\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"faiss\"\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"npy\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".npy\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"faiss\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# examine a pipeline's high level data by using the .config property\n",
    "# print a dictionary nicely in an ide or notebook\n",
    "json_print(reloaded_pipeline.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Modules - advanced details\n",
    "\n",
    "This section contains advanced topics on module usage.  This includes the discussion of additional module data properties - `click_data` and `_example`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "\n",
    "# create a few modules\n",
    "module_1 = Module(module_type='transcribe')\n",
    "module_2 = Module(module_type='text-embedder')\n",
    "module_3 = Module(module_type=\"vector-search\")\n",
    "module_4 = Module(module_type=\"parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Viewing a module's `click_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module property `click_data` displays all the basic data required to know which other modules it can be \"clicked\" into in a pipeline.  This is precisely what data is referenced \"under the hood\" of krixik when you build a pipeline using the `pipeline` api.\n",
    "\n",
    "First there's the module's input / output data format.  A module like  `transcribe` takes in `audio` and outputs `json`, while the `text-embedder` takes in `json` and outputs `.npy`.  \n",
    "\n",
    "Checking that the *output* format of a module matches the *input* format of another module is the *first* of two steps in determining if two modules can be clicked together.  If the output format of \"module A\"  matches the input format of \"module B\" you'll likely be able to connect \"module A\" --> \"module B\" in a pipeline.\n",
    "\n",
    "The *second* step to determine module click-ability is to make sure the input/output  `process_type`'s match.  A module might input a `json` format, but only *process* on certain key-value pairs of it.  \n",
    "\n",
    "Checking this aligment of `process_type` guarantees modules can be connected.\n",
    "\n",
    "Lets take a look at the `click_data` of two modules and discuss what it says about their \"click-ability\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"module_name\": \"text-embedder\",\n",
      "  \"input_format\": \"json\",\n",
      "  \"output_format\": \"npy\",\n",
      "  \"input_process_key\": \"snippet\",\n",
      "  \"input_process_type\": \"<class 'str'>\",\n",
      "  \"output_process_key\": \"data\",\n",
      "  \"output_process_type\": \"<class 'numpy.ndarray'>\"\n",
      "}\n",
      "{\n",
      "  \"module_name\": \"vector-search\",\n",
      "  \"input_format\": \"npy\",\n",
      "  \"output_format\": \"faiss\",\n",
      "  \"input_process_key\": \"data\",\n",
      "  \"input_process_type\": \"<class 'numpy.ndarray'>\",\n",
      "  \"output_process_key\": null,\n",
      "  \"output_process_type\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# examine a module's \"click-ability\" data by using the click_data property\n",
    "# print a dictionary nicely in an ide or notebook\n",
    "json_print(module_2.click_data)\n",
    "json_print(module_3.click_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data suggests that we can \"click\" the modules together like this:\n",
    "\n",
    "`text-embedder` -> `vector-search`\n",
    "\n",
    "but *not* like this\n",
    "\n",
    " `vector-search` -> `text-embedder`\n",
    "\n",
    "The first module connection (`text-embedder` -> `vector-search`) will work since - from the `click_data` of both modules - we can see that \n",
    "\n",
    "- `text-embedder` output_format (`npy`) == `vector-search` input_format (`npy`), and \n",
    "- `text-embedder` output_process_type (`<class 'numpy.ndarray'>`) == `vector-search` input_process_type (`<class 'numpy.ndarray'>`)\n",
    "\n",
    "\n",
    "The latter connection ( `vector-search` -> `text-embedder`) will not work since we can see from the same data \n",
    "\n",
    "- `vector-search` output_format (`faiss`) != `text-embedder` input_format (`json`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  Viewing a module's i/o details\n",
    "\n",
    "You can use the `._example` property to see an example a module's input/output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"transcript\": \"This is the full transcript.\",\n",
      "  \"segments\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"seek\": 0,\n",
      "      \"start\": 0.0,\n",
      "      \"end\": 10.0,\n",
      "      \"text\": \"This is the\",\n",
      "      \"tokens\": [\n",
      "        20,\n",
      "        34\n",
      "      ],\n",
      "      \"temperature\": 0.0,\n",
      "      \"avg_logprob\": 0.0,\n",
      "      \"compression_ratio\": 0.0,\n",
      "      \"no_speech_prob\": 0.0,\n",
      "      \"confidence\": 0.0,\n",
      "      \"words\": [\n",
      "        {\n",
      "          \"text\": \"This\",\n",
      "          \"start\": 0.0,\n",
      "          \"end\": 1.0,\n",
      "          \"confidence\": 0.5\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"is the\",\n",
      "          \"start\": 1.0,\n",
      "          \"end\": 2.0,\n",
      "          \"confidence\": 0.6\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"seek\": 10,\n",
      "      \"start\": 10.0,\n",
      "      \"end\": 20.0,\n",
      "      \"text\": \"main text\",\n",
      "      \"tokens\": [\n",
      "        44,\n",
      "        101\n",
      "      ],\n",
      "      \"temperature\": 0.0,\n",
      "      \"avg_logprob\": 0.0,\n",
      "      \"compression_ratio\": 0.0,\n",
      "      \"no_speech_prob\": 0.0,\n",
      "      \"confidence\": 0.0,\n",
      "      \"words\": [\n",
      "        {\n",
      "          \"text\": \"main\",\n",
      "          \"start\": 10.0,\n",
      "          \"end\": 11.0,\n",
      "          \"confidence\": 0.7\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"text\",\n",
      "          \"start\": 11.0,\n",
      "          \"end\": 12.0,\n",
      "          \"confidence\": 0.8\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"language\": \"English\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# examine a module's \"click-ability\" data by using the click_data property\n",
    "# print a dictionary nicely in an ide or notebook\n",
    "json_print(module_1.output_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Examining input/output dataclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a deeper understanding of each module's input/output data structure you can examine its associated dataclasses.\n",
    "\n",
    "As an example the first module in our `text_search_pipeline` pipeline is `parser`.  The io dataclasss for this module is shown below.  Your input must match this class requirement in order for your input test to pass, and in order for your pipeline to function propertly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@dataclass\n",
      "class InputStructure:\n",
      "    format: Literal[\"text\"] = \"text\"\n",
      "    filename: str = \"input_text.txt\"\n",
      "    process_key: None = None\n",
      "\n",
      "    @property\n",
      "    def data_example(self):\n",
      "        return \"sample text looks like this.\"\n",
      "\n",
      "    @property\n",
      "    def process_type(self):\n",
      "        return (\n",
      "            str(self.__annotations__[self.process_key])\n",
      "            if self.process_key is not None\n",
      "            else None\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load in io.py from krixik.modules.parser\n",
    "from krixik.modules.parser import io\n",
    "import inspect\n",
    "print(inspect.getsource(io.InputStructure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Pipelines - advanced details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1   Building a pipeline one module at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build and ad modules one-at-a-time as well using the `.add` api.  Each time a module is added the same sort of connection test described above is performed on the entire module chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krixik.pipeline_builder.module import Module\n",
    "from krixik.pipeline_builder.pipeline import CreatePipeline\n",
    "\n",
    "# define a module\n",
    "module_1 = Module(module_type='transcribe')\n",
    "\n",
    "# instantiate an empty custom pipeline\n",
    "pipeline = CreatePipeline(name='my-custom-pipeline')\n",
    "\n",
    "# add the first module to the pipeline\n",
    "pipeline.add(module_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define another module\n",
    "module_2 = Module(module_type='sentiment')\n",
    "\n",
    "# add the second module to the pipeline\n",
    "pipeline.add(module_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define another module\n",
    "module_3 = Module(module_type='translate')\n",
    "\n",
    "# add the third module to the pipeline\n",
    "pipeline.add(module_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use all of the previously detailed attributes to view your pipelines configuration.  For example the `.config` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipeline\": {\n",
      "    \"name\": \"my-custom-pipeline\",\n",
      "    \"modules\": [\n",
      "      {\n",
      "        \"name\": \"transcribe\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"whisper-tiny\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"whisper-base\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"whisper-small\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"whisper-medium\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"whisper-large-v3\"\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"whisper-tiny\"\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"audio\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".mp3\",\n",
      "            \".mp4\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"json\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"sentiment\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"bert-base-multilingual-uncased-sentiment\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"distilbert-base-multilingual-cased-sentiments-student\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"distilroberta-finetuned-financial-news-sentiment-analysis\"\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"json\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".json\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"json\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"translate\",\n",
      "        \"models\": [\n",
      "          {\n",
      "            \"name\": \"opus-mt-de-en\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"opus-mt-en-es\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"opus-mt-es-en\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"opus-mt-en-fr\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"opus-mt-fr-en\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"opus-mt-it-en\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"opus-mt-zh-en\"\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"model\": \"opus-mt-en-es\"\n",
      "        },\n",
      "        \"input\": {\n",
      "          \"type\": \"json\",\n",
      "          \"permitted_extensions\": [\n",
      "            \".json\"\n",
      "          ]\n",
      "        },\n",
      "        \"output\": {\n",
      "          \"type\": \"json\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# examine a pipeline's config\n",
    "# print a dictionary nicely in an ide or notebook\n",
    "json_print(pipeline.config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
